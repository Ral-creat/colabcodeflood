# -*- coding: utf-8 -*-
"""FloodPatternv2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SugrpGYCGtltjIRFx3GLpJFPxZXTVLSa
"""



"""# Task
Create a code that will upload the data, will display the characteristic of the data, content of the data, then analyze the data and suggest best preprocessing methods to be applied

## Upload data

### Subtask:
Provide a way for the user to upload their data file.

**Reasoning**:
Import the `files` module and call the `upload()` method to allow the user to upload a file.
"""

from google.colab import files

uploaded_file = files.upload()

"""## Show predictions for each month

### Subtask:
Generate predictions for each month using the trained model and display them.

**Reasoning**:
Create a DataFrame representing each month with typical values for other features, generate predictions using the trained model, and display the predicted flood probability for each month.
"""

import numpy as np

# Create a DataFrame with each month and median values for numerical features
# We use the median as a representative value for the numerical features
median_values = X[['Water Level', 'No. of Families affected', 'Damage Infrastructure', 'Damage Agriculture']].median().to_dict()

# Create a list of months
months = sorted(df['Month'].unique())

# Create a list to store prediction data
prediction_data = []

for month in months:
    # Create a dictionary for the current month with dummy variables
    month_data = {col: False for col in month_dummies.columns}
    month_data[f'Month_{month}'] = True

    # Add median numerical values
    month_data.update(median_values)

    prediction_data.append(month_data)

# Create a DataFrame from the prediction data
prediction_df = pd.DataFrame(prediction_data)

# Ensure the columns are in the same order as the training data
prediction_df = prediction_df[X.columns]

# Generate predictions (probability of flood occurrence)
# We use predict_proba to get the probability of each class (0 and 1)
# The second column [:, 1] is the probability of class 1 (flood occurred)
monthly_predictions = model.predict_proba(prediction_df)[:, 1]

# Create a Series for better display
monthly_predictions_series = pd.Series(monthly_predictions, index=months)

# Print the predicted flood probability for each month
print("Predicted Flood Probability for Each Month:")
print(monthly_predictions_series.sort_values(ascending=False))

"""## Explain the prediction model

### Subtask:
Explain the Random Forest Classifier model used for prediction.

**Reasoning**:
Provide a clear and concise explanation of how the Random Forest Classifier model works in the context of this flood prediction task.
"""

print("### Explanation of the Random Forest Classifier Model")

print("\nThe Random Forest Classifier is an ensemble learning method used for classification tasks. It works by building multiple decision trees during training and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.")

print("\nIn this context, the Random Forest model is used to predict whether a flood is likely to occur (`flood_occurred` = 1) or not (`flood_occurred` = 0) based on the input features, including the month of the year, water level, number of affected families, and damage information.")

print("\nHere's a simplified breakdown of how it works for our flood prediction:")
print("1.  **Multiple Decision Trees:** The algorithm constructs a collection of decision trees. Each tree is trained on a random subset of the data (bootstrapping) and considers a random subset of the features at each split point.")
print("2.  **Independent Training:** Each decision tree is trained independently.")
print("3.  **Prediction by Majority Vote:** To make a prediction for a new instance (e.g., a specific month with certain conditions), the input is passed down each of the decision trees. Each tree makes its own prediction (either 'flood occurred' or 'no flood'). The final prediction of the Random Forest is the class that receives the majority of votes from all the individual trees.")
print("4.  **Handling Complexity and Reducing Overfitting:** By combining the predictions of multiple trees, the Random Forest model tends to be more robust, less prone to overfitting (memorizing the training data instead of generalizing), and can handle complex relationships between features.")

print("\nIn our analysis, the Random Forest model was trained on the historical flood data with the engineered month features and other relevant columns. The model learned the patterns and relationships in the data that lead to flood occurrences. We then used this trained model to predict the probability of flooding for each month, assuming typical values for the other numerical features.")

"""## Load data

### Subtask:
Load the uploaded data into a suitable data structure, like a pandas DataFrame.

**Reasoning**:
Import the pandas library and load the uploaded data into a DataFrame.
"""

import pandas as pd
import io

df = pd.read_csv(io.BytesIO(uploaded_file['FloodDataMDRRMO.csv']))

"""## Display characteristics

### Subtask:
Show key characteristics of the dataset, such as the number of rows and columns, data types, and summary statistics.

**Reasoning**:
Display the shape, data types, and summary statistics of the DataFrame to understand its characteristics.
"""

print("Shape of the DataFrame:")
print(df.shape)

print("\nData types of columns:")
df.info()

print("\nDescriptive statistics of numerical columns:")
display(df.describe())

"""## Display content

### Subtask:
Display the first few rows of the dataset to show its content.

**Reasoning**:
Display the first few rows of the dataframe to show its content.
"""

display(df.head())

"""## Analyze data

### Subtask:
Analyze the data for potential issues that might require preprocessing, such as missing values, outliers, or inconsistent data types.

**Reasoning**:
Check for missing values in each column and investigate the data types of columns that should be numerical but are currently objects, examining them for non-numerical entries.
"""

print("Missing values per column:")
print(df.isnull().sum())

print("\nData types:")
print(df.dtypes)

print("\nUnique values in 'Water Level':")
print(df['Water Level'].unique())

print("\nUnique values in 'Damage Infrastructure':")
print(df['Damage Infrastructure'].unique())

print("\nUnique values in 'Damage Agriculture':")
print(df['Damage Agriculture'].unique())

"""## Suggest preprocessing methods

### Subtask:
Based on the analysis, suggest appropriate preprocessing techniques.

**Reasoning**:
Based on the analysis, identify columns requiring preprocessing and suggest appropriate techniques for each issue found.
"""

print("Columns requiring preprocessing and suggested techniques:")

# Month, Day, Year: Missing values.
print("\n- Columns: Month, Day, Year")
print("  Issues: Missing values.")
print("  Suggested Preprocessing: Imputation (e.g., forward fill or backward fill if data is time-series ordered, or a placeholder value if not).")

# Water Level: Missing values, inconsistent formatting (text and numbers).
print("\n- Column: Water Level")
print("  Issues: Missing values, inconsistent formatting (contains ' ft.', 'ft', spaces, and non-numeric entries), incorrect data type (object).")
print("  Suggested Preprocessing: Remove non-numeric characters and text (' ft.', 'ft', spaces), convert to numeric type (float or int), impute missing values (e.g., mean, median, or a placeholder).")

# No. of Families affected: Incorrect data type (object).
print("\n- Column: No. of Families affected")
print("  Issues: Incorrect data type (object).")
print("  Suggested Preprocessing: Convert to numeric type (int or float).")

# Damage Infrastructure, Damage Agriculture: Missing values, inconsistent formatting (commas, periods), incorrect data type (object).
print("\n- Columns: Damage Infrastructure, Damage Agriculture")
print("  Issues: Missing values, inconsistent formatting (contains commas ',' and periods '.'), incorrect data type (object).")
print("  Suggested Preprocessing: Remove commas, convert to numeric type (float), impute missing values (e.g., mean, median, or 0 if it implies no damage).")

# Outliers in numerical columns (after conversion):
print("\n- Potential Outliers:")
print("  Issues: Outliers may exist in numerical columns (Day, Year, No. of Families affected, Damage Infrastructure, Damage Agriculture) after conversion.")
print("  Suggested Handling: Analyze distribution using visualizations (histograms, box plots), consider capping, transformation, or removal depending on the nature and impact of outliers.")

print("\nOverall Preprocessing Strategy:")
print("1. Handle missing values in 'Month', 'Day', 'Year' through imputation.")
print("2. Clean and convert 'Water Level', 'No. of Families affected', 'Damage Infrastructure', and 'Damage Agriculture' to appropriate numeric types.")
print("3. Handle missing values in the converted numeric columns through imputation.")
print("4. Investigate and handle potential outliers in numerical columns.")

"""## Summary:

### Data Analysis Key Findings

*   The dataset contains 155 rows and 10 columns.
*   The data includes a mix of data types, with 2 columns initially identified as `float64` and 8 as `object`.
*   Several columns have missing values, including 'Month', 'Day', 'Year', 'Water Level', 'Damage Infrastructure', and 'Damage Agriculture'.
*   Columns that should contain numerical data ('Water Level', 'No. of Families affected', 'Damage Infrastructure', and 'Damage Agriculture') are currently stored as `object` type due to inconsistent formatting (e.g., text, spaces, commas, and periods used as decimal separators).
*   The 'Water Level' column contains text like ' ft.' and 'ft' mixed with numerical values.
*   The 'Damage Infrastructure' and 'Damage Agriculture' columns contain commas and periods that prevent them from being read as pure numerical values.

### Insights or Next Steps

*   The primary next step is to implement the suggested preprocessing steps, focusing on cleaning and converting the 'object' type numerical columns and handling missing values.
*   After cleaning and converting the relevant columns to numeric types, further analysis for outliers in these and other numerical columns is recommended.

# Task
Analyze the data in the file "Water_Level_Data.csv", visualize the 'Water Level' column, and suggest preprocessing methods.

## Clean 'water level' column

### Subtask:
Remove non-numeric characters and text (' ft.', 'ft', spaces) from the 'Water Level' column.

**Reasoning**:
Remove ' ft.', 'ft', and spaces from the 'Water Level' column to prepare it for conversion to a numeric type.
"""

df['Water Level'] = df['Water Level'].astype(str).str.replace(' ft.', '', regex=False).str.replace(' ft', '', regex=False).str.replace(' ', '', regex=False)
display(df['Water Level'].unique())

"""**Reasoning**:
The 'Water Level' column still contains '5ft' and 'nan'. I will remove 'ft' and replace 'nan' with NaN to make it suitable for numeric conversion.


"""

df['Water Level'] = df['Water Level'].str.replace('ft', '', regex=False).replace('nan', pd.NA)
display(df['Water Level'].unique())

"""## Convert 'water level' to numeric

### Subtask:
Convert the cleaned 'Water Level' column to a numeric type (float or int).

**Reasoning**:
Convert the cleaned 'Water Level' column to a numeric type, coercing errors to NaN, and then display the data types to verify the conversion.
"""

df['Water Level'] = pd.to_numeric(df['Water Level'], errors='coerce')
print("\nData types after converting 'Water Level':")
print(df.dtypes)

"""## Handle missing values

### Subtask:
Impute missing values in the 'Water Level' column after conversion.

**Reasoning**:
Calculate the median of the 'Water Level' column and fill the missing values with this median. Then verify the imputation.
"""

median_water_level = df['Water Level'].median()
df['Water Level'].fillna(median_water_level, inplace=True)
print("Missing values in 'Water Level' after imputation:")
print(df['Water Level'].isnull().sum())

"""## Visualize 'water level'

### Subtask:
Create a visualization (e.g., histogram or box plot) to show the distribution of the cleaned and converted 'Water Level' data.

**Reasoning**:
Create a histogram to visualize the distribution of the cleaned and imputed 'Water Level' data.
"""

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.hist(df['Water Level'], bins=20, edgecolor='black')
plt.title('Distribution of Water Level')
plt.xlabel('Water Level')
plt.ylabel('Frequency')
plt.show()

"""## Summary:

### Data Analysis Key Findings

*   Non-numeric characters and text (' ft.', 'ft', spaces) were successfully removed from the 'Water Level' column.
*   The 'Water Level' column was successfully converted to a numeric data type (float64).
*   Missing values in the 'Water Level' column were imputed using the median value.
*   A histogram visualizing the distribution of the cleaned and imputed 'Water Level' data was successfully generated.

### Insights or Next Steps

*   The distribution of the water level can be observed from the histogram, which can inform further analysis or modeling.
*   Consider analyzing the temporal trends of the water level if a time-based column is available in the dataset.

# Task
Perform a KDD process on the cleaned dataset, including data cleaning, data integration, data selection, data transformation, data mining, pattern evaluation, and knowledge representation.

## Continue data cleaning

### Subtask:
Address the remaining data quality issues identified in the initial analysis, such as handling missing values and inconsistent formats in other relevant columns ('Month', 'Day', 'Year', 'No. of Families affected', 'Damage Infrastructure', 'Damage Agriculture').

**Reasoning**:
Examine 'No. of Families affected' for non-numeric entries, clean and convert to numeric, then impute missing values. Also, examine 'Damage Infrastructure' and 'Damage Agriculture' for non-numeric entries, clean and convert to numeric, and impute missing values. Finally, impute missing values for 'Month', 'Day', and 'Year' and display missing values and data types to verify cleaning.
"""

# 1. Examine 'No. of Families affected' for non-numeric entries (excluding NaNs)
print("Unique non-numeric values in 'No. of Families affected':")
non_numeric_families = df['No. of Families affected'][pd.to_numeric(df['No. of Families affected'], errors='coerce').isna()].unique()
print(non_numeric_families)

# 2. Clean and convert 'No. of Families affected' to numeric
df['No. of Families affected'] = pd.to_numeric(df['No. of Families affected'], errors='coerce')

# 3. Impute missing values in 'No. of Families affected' using median
median_families = df['No. of Families affected'].median()
df['No. of Families affected'].fillna(median_families, inplace=True)

# 4. Examine 'Damage Infrastructure' and 'Damage Agriculture' for non-numeric entries (excluding commas, periods, and NaNs)
print("\nUnique non-numeric values in 'Damage Infrastructure':")
non_numeric_infra = df['Damage Infrastructure'].astype(str).str.replace(',', '', regex=False).str.replace('.', '', regex=False)[pd.to_numeric(df['Damage Infrastructure'].astype(str).str.replace(',', '', regex=False).str.replace('.', '', regex=False), errors='coerce').isna()].unique()
print(non_numeric_infra)

print("\nUnique non-numeric values in 'Damage Agriculture':")
non_numeric_agri = df['Damage Agriculture'].astype(str).str.replace(',', '', regex=False).str.replace('.', '', regex=False)[pd.to_numeric(df['Damage Agriculture'].astype(str).str.replace(',', '', regex=False).str.replace('.', '', regex=False), errors='coerce').isna()].unique()
print(non_numeric_agri)


# 5. Clean and convert 'Damage Infrastructure' and 'Damage Agriculture' to numeric
df['Damage Infrastructure'] = df['Damage Infrastructure'].astype(str).str.replace(',', '', regex=False)
df['Damage Infrastructure'] = pd.to_numeric(df['Damage Infrastructure'], errors='coerce')

df['Damage Agriculture'] = df['Damage Agriculture'].astype(str).str.replace(',', '', regex=False)
# Replace the identified inconsistent period with nothing before converting to numeric
df['Damage Agriculture'] = df['Damage Agriculture'].str.replace('422.510.5', '4225105', regex=False)
df['Damage Agriculture'] = pd.to_numeric(df['Damage Agriculture'], errors='coerce')

# 6. Impute missing values in 'Damage Infrastructure' and 'Damage Agriculture' using 0 (assuming 0 damage for missing values)
df['Damage Infrastructure'].fillna(0, inplace=True)
df['Damage Agriculture'].fillna(0, inplace=True)

# 7. Impute missing values for 'Month', 'Day', and 'Year'. Using backward fill assuming some chronological order within groups.
df['Month'].fillna(method='bfill', inplace=True)
df['Day'].fillna(method='bfill', inplace=True)
df['Year'].fillna(method='bfill', inplace=True)


# 8. Display the number of missing values for all columns
print("\nMissing values per column after cleaning and imputation:")
print(df.isnull().sum())

# 9. Display the data types of all columns
print("\nData types after cleaning and imputation:")
print(df.dtypes)

"""## Data integration (if applicable)

### Subtask:
Determine if there are any other relevant data sources that could be integrated with the current dataset and if so, outline a strategy for integration.

## Data selection

### Subtask:
Select the relevant columns from the cleaned dataset for data mining, based on the insights gained from data analysis and the goals of the KDD process.

**Reasoning**:
Select the relevant columns for data mining based on the analysis and display the head and data types of the resulting DataFrame.
"""

# Select relevant columns
selected_columns_df = df[['Municipality', 'Barangay', 'Flood Cause', 'Water Level', 'No. of Families affected', 'Damage Infrastructure', 'Damage Agriculture']]

# Display the first few rows of the new DataFrame
print("First few rows of the selected columns DataFrame:")
display(selected_columns_df.head())

# Display the columns and data types of the new DataFrame
print("\nColumns and data types of the selected columns DataFrame:")
print(selected_columns_df.dtypes)

"""## Data transformation

### Subtask:
Transform the selected data into a format suitable for data mining. This might involve feature engineering, aggregation, or normalization.

**Reasoning**:
Identify categorical columns, apply one-hot encoding, and consider scaling for numerical columns.
"""

# Identify categorical columns
categorical_cols = selected_columns_df.select_dtypes(include='object').columns
print("Categorical columns to encode:", categorical_cols)

# Apply one-hot encoding
encoded_df = pd.get_dummies(selected_columns_df, columns=categorical_cols, dummy_na=False)

# Numerical columns for potential scaling (excluding the encoded ones)
numerical_cols = encoded_df.select_dtypes(include=['float64', 'int64']).columns
print("\nNumerical columns:", numerical_cols)

# While scaling might be beneficial for some algorithms, let's skip it for now
# as the ranges of numerical features are not drastically different and
# tree-based models are less sensitive to feature scaling.
# If needed, StandardScaler or MinMaxScaler could be applied here.

# Display the first few rows of the transformed DataFrame
print("\nFirst few rows of the transformed DataFrame:")
display(encoded_df.head())

# Display the data types of the transformed DataFrame
print("\nData types of the transformed DataFrame:")
print(encoded_df.dtypes)

"""## Data mining

### Subtask:
Apply data mining techniques (e.g., clustering, classification, association rule mining) to discover patterns and insights in the data.

**Reasoning**:
Apply K-Means clustering to the transformed data to group similar flood events.
"""

from sklearn.cluster import KMeans

# Determine the optimal number of clusters (e.g., using the elbow method or domain knowledge)
# For demonstration, let's choose a reasonable number of clusters, e.g., 3
n_clusters = 3

# Instantiate the KMeans model
kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)

# Fit the model to the transformed data
kmeans.fit(encoded_df)

# Add the cluster labels to the original DataFrame (or the selected columns DataFrame)
df['Cluster'] = kmeans.labels_

# Display the count of instances in each cluster
print("Count of instances in each cluster:")
print(df['Cluster'].value_counts())

# Display the first few rows with the new cluster labels
print("\nFirst few rows with cluster labels:")
display(df.head())

"""## Pattern evaluation

### Subtask:
Evaluate the discovered patterns (clusters) by analyzing the characteristics of each cluster.

**Reasoning**:
Group the DataFrame by 'Cluster' and calculate descriptive statistics for the numerical columns to understand the characteristics of each cluster. Also, examine the value counts of categorical columns within each cluster.
"""

# Group by cluster and calculate descriptive statistics for numerical columns
cluster_summary_numerical = df.groupby('Cluster')[['Water Level', 'No. of Families affected', 'Damage Infrastructure', 'Damage Agriculture']].agg(['count', 'mean', 'median', 'std']).reset_index()
print("Descriptive statistics of numerical columns per cluster:")
display(cluster_summary_numerical)

# Examine categorical columns per cluster
categorical_cols = ['Municipality', 'Barangay', 'Flood Cause']
for col in categorical_cols:
    print(f"\nDistribution of '{col}' per cluster:")
    cluster_summary_categorical = df.groupby('Cluster')[col].value_counts(normalize=True).unstack(fill_value=0)
    display(cluster_summary_categorical)

"""**Reasoning**:
Summarize the evaluation of the clusters based on the descriptive statistics and categorical distributions, highlighting the key characteristics of each cluster as the pattern evaluation step of the KDD process.


"""

print("Cluster Evaluation Summary:")

print("\nCluster 0:")
print("- Characterized by the vast majority of instances (144).")
print("- Relatively lower mean and median Water Level compared to other clusters.")
print("- Lower mean and median 'No. of Families affected', 'Damage Infrastructure', and 'Damage Agriculture' compared to other clusters, suggesting less severe flood events.")
print("- Dominant Flood Cause is 'Low Pressure Area (LPA)' (47.9%), with occurrences across various barangays.")

print("\nCluster 1:")
print("- Contains a small number of instances (7).")
print("- Higher mean 'Water Level' and 'No. of Families affected' than Cluster 0, but lower than Cluster 2 in some aspects.")
print("- Significantly higher mean and median 'Damage Agriculture' compared to Cluster 0 and Cluster 2, indicating events with substantial agricultural impact.")
print("- Notable occurrences of 'Easterlies and Shearline', 'Low Pressure Area (LPA)', and 'Tropical Depression AURING' as Flood Causes.")
print("- Events distributed across several barangays, with a notable proportion in 'Poblacion' and 'Mambalili'.")

print("\nCluster 2:")
print("- The smallest cluster with only 4 instances.")
print("- Highest mean 'Water Level' and 'Damage Infrastructure' among all clusters, suggesting the most severe flood events in terms of water depth and infrastructure damage.")
print("- Median 'Damage Infrastructure' is also the highest.")
print("- 'Easterlies and Shearline' and 'Low Pressure Area (LPA)' are the primary Flood Causes.")
print("- Events predominantly in 'Bunawan Brook' and 'Imelda', with some in 'Poblacion'.")

print("\nOverall:")
print("The clustering has identified three distinct patterns of flood events based on the selected features:")
print("- Cluster 0: Represents the most frequent, less severe flood events with moderate impacts, primarily due to LPAs.")
print("- Cluster 1: Represents less frequent events with moderate water levels and family impact but very high agricultural damage, caused by a mix of weather phenomena.")
print("- Cluster 2: Represents rare, highly severe flood events characterized by high water levels and significant infrastructure damage, mainly due to Easterlies/Shearline and LPAs, concentrated in specific barangays.")

"""## Knowledge representation

### Subtask:
Present the discovered knowledge (cluster characteristics and insights) in a clear and understandable way.

**Reasoning**:
Present the key characteristics and insights of each cluster based on the pattern evaluation, highlighting the typical values for water level, affected families, and damage, the dominant flood causes, notable locations, and practical implications.
"""

print("## Discovered Knowledge and Insights from Flood Event Clustering")

print("\nBased on the K-Means clustering of flood events, three distinct patterns or clusters have been identified, each with unique characteristics and implications:")

print("\n### Cluster 0: Frequent, Lower Impact Events")
print("- **Characteristics:** This is the largest cluster, representing the most frequent flood events. These events typically have lower water levels, fewer affected families, and less damage to both infrastructure and agriculture compared to the other clusters.")
print(f"- **Typical Values (Median):** Water Level: {cluster_summary_numerical.loc[0, ('Water Level', 'median')]} ft, Families Affected: {cluster_summary_numerical.loc[0, ('No. of Families affected', 'median')]}, Infrastructure Damage: {cluster_summary_numerical.loc[0, ('Damage Infrastructure', 'median')]}, Agriculture Damage: {cluster_summary_numerical.loc[0, ('Damage Agriculture', 'median')]}.")
print("- **Dominant Flood Cause:** Primarily associated with 'Low Pressure Area (LPA)'.")
print("- **Notable Locations:** Events in this cluster are widely distributed across various barangays.")
print("- **Practical Implications:** This cluster highlights the baseline flood risk and the typical scale of events the community experiences most often. Preparedness efforts should focus on widespread awareness and basic response mechanisms for these frequent, less severe floods.")

print("\n### Cluster 1: Less Frequent, High Agricultural Impact Events")
print("- **Characteristics:** This is a smaller cluster representing less frequent events. While water levels and the number of affected families are moderate, these events are characterized by significantly higher damage to agriculture.")
print(f"- **Typical Values (Median):** Water Level: {cluster_summary_numerical.loc[1, ('Water Level', 'median')]} ft, Families Affected: {cluster_summary_numerical.loc[1, ('No. of Families affected', 'median')]}, Infrastructure Damage: {cluster_summary_numerical.loc[1, ('Damage Infrastructure', 'median')]}, Agriculture Damage: {cluster_summary_numerical.loc[1, ('Damage Agriculture', 'median')]:,.2f}.") # Format agriculture damage for readability
print("- **Dominant Flood Causes:** Associated with a mix of weather phenomena including 'Easterlies and Shearline', 'Low Pressure Area (LPA)', and 'Tropical Depression AURING'.")
print("- **Notable Locations:** Specific barangays like 'Poblacion' and 'Mambalili' show a notable proportion of events in this cluster.")
print("- **Practical Implications:** This cluster points to a specific vulnerability in certain areas – agricultural damage. Targeted interventions for these locations could include flood-resistant crop varieties, improved drainage in agricultural lands, or specific agricultural insurance programs. Early warning systems should consider the potential for agricultural impact during these types of weather events.")

print("\n### Cluster 2: Rare, Highly Severe Events")
print("- **Characteristics:** This is the smallest cluster, representing rare but highly severe flood events. These events are marked by the highest water levels and significant damage to infrastructure.")
print(f"- **Typical Values (Median):** Water Level: {cluster_summary_numerical.loc[2, ('Water Level', 'median')]} ft, Families Affected: {cluster_summary_numerical.loc[2, ('No. of Families affected', 'median')]}, Infrastructure Damage: {cluster_summary_numerical.loc[2, ('Damage Infrastructure', 'median')]:,.2f}, Agriculture Damage: {cluster_summary_numerical.loc[2, ('Damage Agriculture', 'median')]:,.2f}.") # Format damage for readability
print("- **Dominant Flood Causes:** Primarily linked to 'Easterlies and Shearline' and 'Low Pressure Area (LPA)'.")
print("- **Notable Locations:** Events in this cluster are predominantly concentrated in 'Bunawan Brook' and 'Imelda'.")
print("- **Practical Implications:** This cluster highlights critical areas and conditions that lead to the most devastating floods. Disaster preparedness for these events should focus on robust infrastructure planning (e.g., elevated structures, improved drainage systems), establishing well-equipped evacuation centers, and prioritizing resource allocation to the identified high-risk barangays during these specific weather patterns. Early and clear communication of severe flood warnings is crucial for these rare but impactful events.")

print("\n### Overall Practical Implications:")
print("The identified clusters provide actionable insights for the MDRRMO:")
print("- **Targeted Resource Allocation:** Resources (personnel, equipment, relief goods) can be pre-positioned or prioritized based on the expected cluster type and its associated impact and location.")
print("- **Tailored Preparedness Plans:** Preparedness strategies can be customized for different types of flood events and their likely locations. For example, agricultural support is critical for Cluster 1 areas, while infrastructure reinforcement and robust evacuation plans are paramount for Cluster 2 locations.")
print("- **Improved Early Warning Systems:** Understanding the flood causes associated with each cluster can help refine early warning systems to better predict the potential severity and impact of an approaching weather event.")
print("- **Informed Urban Planning:** The concentration of severe events in specific barangays (Cluster 2) can inform urban planning and infrastructure development decisions to mitigate future risks in these areas.")

"""## Summary:

### Data Analysis Key Findings

*   After cleaning and imputation, the "No. of Families affected", "Damage Infrastructure", and "Damage Agriculture" columns had no missing values and were converted to `float64`.
*   Nine missing values remained in "Month", "Day", and "Year" after backward imputation.
*   Three distinct clusters of flood events were identified using K-Means clustering, with a highly uneven distribution of instances: Cluster 0 (144 instances), Cluster 1 (7 instances), and Cluster 2 (4 instances).
*   Cluster 0 represents frequent, less severe floods with lower impacts on families and damage, primarily caused by Low Pressure Areas (LPAs) and spread across locations.
*   Cluster 1 represents less frequent events with moderate impact on families and water level, but significantly high agricultural damage, linked to Easterlies/Shearline, LPAs, and Tropical Depression AURING in specific barangays like Poblacion and Mambalili.
*   Cluster 2 represents rare, highly severe floods characterized by the highest water levels and significant infrastructure damage, mainly due to Easterlies/Shearline and LPAs, concentrated in Bunawan Brook and Imelda.

### Insights or Next Steps

*   Develop tailored flood preparedness and response strategies for each identified cluster type, focusing on resource allocation and early warning systems based on the predicted cluster and its associated impact and location.
*   Investigate the specific vulnerabilities and characteristics of barangays highlighted in Clusters 1 (agricultural damage focus) and 2 (infrastructure damage focus) to implement targeted mitigation measures like improved drainage or infrastructure reinforcement.

# Task
Analyze the data to determine the months most likely to flood and visualize the monthly flood patterns.

## Prepare data for prediction

### Subtask:
Ensure the data is in a format suitable for training a predictive model. This might involve creating a target variable (e.g., indicating whether a flood occurred or the severity of the flood) and selecting relevant features.

**Reasoning**:
Create a binary target variable 'flood_occurred' based on whether the 'Water Level' is greater than 0, display the head and data types of the updated DataFrame to verify the new column and its type.
"""

# Create a binary target variable 'flood_occurred'
df['flood_occurred'] = (df['Water Level'] > 0).astype(int)

# Display the first few rows with the new target variable
print("First few rows with 'flood_occurred' column:")
display(df.head())

# Display the data types to verify the new column's type
print("\nData types after adding 'flood_occurred':")
print(df.dtypes)

"""## Feature engineering (month)

### Subtask:
Feature engineering (month)

**Reasoning**:
Extract the month name from the 'Month' column, handle remaining missing values, and create dummy variables for the month names. Then, display the head and data types of the DataFrame.
"""

# Extract month name and handle missing values
df['Month'] = df['Month'].fillna('Unknown')

# Create dummy variables for month names
month_dummies = pd.get_dummies(df['Month'], prefix='Month')

# Concatenate the dummy variables with the original DataFrame
df = pd.concat([df, month_dummies], axis=1)

# Display the first few rows with the new dummy variables
print("First few rows with month dummy variables:")
display(df.head())

# Display the data types to verify the new columns' types
print("\nData types after adding month dummy variables:")
print(df.dtypes)

"""## Select features and target

### Subtask:
Select the features (input variables) and the target variable (what you want to predict).

**Reasoning**:
Define features and target variable, then create X and y DataFrames and display their heads and dtypes.
"""

# Define feature columns including numerical and month dummy variables
feature_cols = ['Water Level', 'No. of Families affected', 'Damage Infrastructure', 'Damage Agriculture'] + list(month_dummies.columns)

# Define the target variable
target_col = 'flood_occurred'

# Create the feature matrix X
X = df[feature_cols]

# Create the target vector y
y = df[target_col]

# Print the first few rows of X and y
print("First few rows of X (features):")
display(X.head())

print("\nFirst few rows of y (target):")
display(y.head())

# Print the data types of X and y
print("\nData types of X:")
print(X.dtypes)

print("\nData types of y:")
print(y.dtypes)

"""## Choose and train a predictive model

### Subtask:
Choose and train a predictive model

**Reasoning**:
Import the RandomForestClassifier model and train it using the features (X) and target (y) dataframes.
"""

from sklearn.ensemble import RandomForestClassifier

# Instantiate the RandomForestClassifier model
model = RandomForestClassifier(random_state=42)

# Train the model
model.fit(X, y)

print("Model training complete.")

"""## Evaluate the model

### Subtask:
Evaluate the performance of the trained model using appropriate metrics.

**Reasoning**:
Split the data, predict on the test set, and evaluate the model using accuracy and a classification report to assess its performance.
"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

# 1. Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 2. Predict the target variable on the test set
y_pred = model.predict(X_test)

# 3. Calculate the accuracy
accuracy = accuracy_score(y_test, y_pred)

# 4. Print the calculated accuracy
print(f"Accuracy of the model: {accuracy:.4f}")

# 5. Calculate and print other relevant classification metrics
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

"""## Analyze flood patterns by month

### Subtask:
Analyze flood patterns by month

**Reasoning**:
Calculate monthly flood occurrences and probabilities, then sort and print them.
"""

# Calculate total flood occurrences per month
monthly_flood_counts = df.groupby('Month')['flood_occurred'].sum()

# Calculate total entries per month
monthly_total_counts = df.groupby('Month')['flood_occurred'].count()

# Calculate flood probability per month
monthly_flood_probability = monthly_flood_counts / monthly_total_counts

# Sort months by flood probability in descending order
sorted_monthly_flood_probability = monthly_flood_probability.sort_values(ascending=False)

# Print the monthly flood probabilities
print("Monthly Flood Probabilities (Sorted):")
print(sorted_monthly_flood_probability)

"""**Reasoning**:
Visualize the monthly flood probabilities using a bar plot to show the pattern.


"""

import matplotlib.pyplot as plt

# Create a bar plot of monthly flood probabilities
plt.figure(figsize=(12, 7))
sorted_monthly_flood_probability.plot(kind='bar', color='skyblue')
plt.title('Monthly Flood Probability')
plt.xlabel('Month')
plt.ylabel('Probability of Flood Occurrence')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""## Summary:

### Data Analysis Key Findings

*   The months with the highest probability of flooding are December (60%) and February (56.76%).
*   January and November also have a significant probability of flooding (39.74% and 35% respectively).
*   Months like May show no flood occurrences in the dataset (0% probability).
*   The trained RandomForestClassifier model achieved perfect accuracy (1.0000) on the test set, indicating it can accurately predict flood occurrences based on the provided features.

### Insights or Next Steps

*   The analysis clearly identifies the peak flood season, which is late autumn and winter (November to February). This information is crucial for preparedness and resource allocation.
*   Further investigation into the "Unknown" month category could be beneficial to understand if these represent a specific period or data collection issue.

# Task
Analyze the relationship between Municipality and flood occurrence, refine the flood prediction model, and predict flood severity instead of occurrence.

## Explore relationship between municipality and flood occurrence

### Subtask:
Analyze the data to understand how flood occurrences vary across different municipalities. This could involve calculating flood frequency or probability per municipality and visualizing the results.

**Reasoning**:
Calculate flood occurrences and total entries per municipality, then calculate and print the flood probability per municipality, sorted in descending order.
"""

# Calculate total flood occurrences per municipality
municipal_flood_counts = df.groupby('Municipality')['flood_occurred'].sum()

# Calculate total entries per municipality
municipal_total_counts = df.groupby('Municipality')['flood_occurred'].count()

# Calculate flood probability per municipality
municipal_flood_probability = municipal_flood_counts / municipal_total_counts

# Sort municipalities by flood probability in descending order
sorted_municipal_flood_probability = municipal_flood_probability.sort_values(ascending=False)

# Print the municipal flood probabilities
print("Municipal Flood Probabilities (Sorted):")
print(sorted_municipal_flood_probability)

"""**Reasoning**:
Visualize the municipal flood probabilities using a bar plot to show the pattern.


"""

import matplotlib.pyplot as plt

# Create a bar plot of municipal flood probabilities
plt.figure(figsize=(12, 7))
sorted_municipal_flood_probability.plot(kind='bar', color='skyblue')
plt.title('Flood Probability by Municipality')
plt.xlabel('Municipality')
plt.ylabel('Probability of Flood Occurrence')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""## Refine the prediction model

### Subtask:
Refine the existing flood prediction model by including the 'Municipality' and 'Barangay' features and re-evaluating its performance.

**Reasoning**:
Define features including numerical, month, municipality, and barangay dummy variables, define the target, create feature and target dataframes, split the data, train a RandomForestClassifier model, predict on the test set, and evaluate performance using accuracy and classification report.
"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Define feature columns including numerical, month, municipality, and barangay dummy variables
feature_cols_refined = ['Water Level', 'No. of Families affected', 'Damage Infrastructure', 'Damage Agriculture'] + list(month_dummies.columns)

# Add one-hot encoded 'Municipality' and 'Barangay' columns
# Ensure to handle potential missing values before one-hot encoding if not already done
# Based on previous analysis, Municipality and Barangay had no missing values
municipality_dummies = pd.get_dummies(df['Municipality'], prefix='Municipality', dummy_na=False)
barangay_dummies = pd.get_dummies(df['Barangay'], prefix='Barangay', dummy_na=False)

feature_cols_refined.extend(list(municipality_dummies.columns))
feature_cols_refined.extend(list(barangay_dummies.columns))


# Define the target variable
target_col_refined = 'flood_occurred'

# Create the feature matrix X_refined and target vector y_refined
X_refined = pd.concat([df[['Water Level', 'No. of Families affected', 'Damage Infrastructure', 'Damage Agriculture']], month_dummies, municipality_dummies, barangay_dummies], axis=1)
y_refined = df[target_col_refined]

# Split the refined data into training and testing sets
X_train_refined, X_test_refined, y_train_refined, y_test_refined = train_test_split(X_refined, y_refined, test_size=0.3, random_state=42)

# Instantiate a new RandomForestClassifier model
model_refined = RandomForestClassifier(random_state=42)

# Train the new model
model_refined.fit(X_train_refined, y_train_refined)

# Predict the target variable on the refined test set
y_pred_refined = model_refined.predict(X_test_refined)

# Calculate and print the accuracy
accuracy_refined = accuracy_score(y_test_refined, y_pred_refined)
print(f"Refined Model Accuracy: {accuracy_refined:.4f}")

# Calculate and print the classification report
print("\nRefined Model Classification Report:")
print(classification_report(y_test_refined, y_pred_refined))

"""## Predict flood severity

### Subtask:
Change the prediction task from classifying flood occurrence to predicting flood severity.

**Reasoning**:
Define a new target variable for flood severity by categorizing 'Water Level', select features and the new target, choose an appropriate model (classification for severity categories), split the data, train the model, and evaluate its performance.

**Reasoning**:
The previous code failed because the feature columns list was not correctly constructed, leading to a KeyError. The one-hot encoded columns for Municipality and Barangay were created in a previous step but not explicitly included in the list of feature columns for the severity prediction model. I need to correctly include the column names from the previously created dummy dataframes in the feature list and then proceed with selecting the features and training the model.

## Visualize predictions

### Subtask:
Plot the historical data and the predicted values to visualize the model's performance and future forecasts.

**Reasoning**:
Plot the original time series, the fitted values, and the predictions to visualize the model's performance and future forecasts.
"""

import matplotlib.pyplot as plt

# 1. Create a figure and axes for the plot with a specified size.
plt.figure(figsize=(15, 7))

# 2. Plot the original time series data (ts_df_filled)
plt.plot(ts_df_filled.index, ts_df_filled, label='Original (Filled) Time Series')

# 3. Plot the fitted values from the SARIMA model (results_sarima.fittedvalues)
plt.plot(results_sarima.fittedvalues.index, results_sarima.fittedvalues, color='green', label='Fitted Values')

# 4. Plot the future predictions (predictions)
# Ensure the index of predictions is used for plotting
plt.plot(predictions.index, predictions, color='red', label='Predictions')

# 5. Add a title to the plot
plt.title('SARIMA Model Fit and Predictions')

# 6. Label the x-axis
plt.xlabel('Date')

# 7. Label the y-axis
plt.ylabel('Average Water Level')

# 8. Include a legend
plt.legend()

# 9. Display the plot
plt.show()

"""## Evaluate model performance

### Subtask:
Evaluate the performance of the SARIMA model using appropriate time series metrics (e.g., RMSE, MAE).

**Reasoning**:
Calculate and print the RMSE and MAE between the actual and fitted values of the SARIMA model to evaluate its performance using appropriate time series metrics.
"""

from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

# Calculate RMSE and MAE using the fitted values
# Note: fittedvalues are based on the training data
actual_values = ts_df_filled[results_sarima.fittedvalues.index]
fitted_values = results_sarima.fittedvalues

rmse = np.sqrt(mean_squared_error(actual_values, fitted_values))
mae = mean_absolute_error(actual_values, fitted_values)

print(f"SARIMA Model Performance on Training Data:")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")
print(f"Mean Absolute Error (MAE): {mae:.4f}")

"""## Make predictions

### Subtask:
Make predictions using the trained SARIMA model.

**Reasoning**:
Use the trained SARIMA model to predict future values of the time series.
"""

# Make predictions using the trained SARIMA model
# Predict future values
# Define the number of steps ahead to predict
steps_ahead = 30  # Example: Predict for the next 30 days

# Get the index for the future predictions
# We can use the last date in our time series and extend it for the number of steps ahead
last_date = ts_df_filled.index[-1]
future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=steps_ahead, freq='D')

# Make predictions
predictions = results_sarima.predict(start=future_dates[0], end=future_dates[-1])

# Print the predictions
print(f"\nSARIMA Model Predictions for the next {steps_ahead} days:")
print(predictions)

# Plot the original time series, the fitted values, and the predictions
plt.figure(figsize=(15, 7))
plt.plot(ts_df_filled.index, ts_df_filled, label='Original (Filled) Time Series')
plt.plot(results_sarima.fittedvalues.index, results_sarima.fittedvalues, color='green', label='Fitted Values')
plt.plot(predictions.index, predictions, color='red', label='Predictions')
plt.title('SARIMA Model Fit and Predictions')
plt.xlabel('Date')
plt.ylabel('Average Water Level')
plt.legend()
plt.show()

# 1. Define a new target variable for flood severity based on 'Water Level'
# Let's define severity levels:
# Low: Water Level <= 5 ft
# Medium: 5 ft < Water Level <= 15 ft
# High: Water Level > 15 ft
def categorize_severity(water_level):
    if water_level <= 5:
        return 'Low'
    elif 5 < water_level <= 15:
        return 'Medium'
    else:
        return 'High'

df['Flood_Severity'] = df['Water Level'].apply(categorize_severity)

# Display the distribution of the new target variable
print("Distribution of Flood Severity:")
print(df['Flood_Severity'].value_counts())

# 2. Select the features and the new target variable for severity
# We will use the same features as the refined model, excluding the old target and Water Level itself
feature_cols_severity = ['No. of Families affected', 'Damage Infrastructure', 'Damage Agriculture'] + list(month_dummies.columns) + list(municipality_dummies.columns) + list(barangay_dummies.columns)
target_col_severity = 'Flood_Severity'

# Ensure all feature columns exist in the DataFrame before selection
missing_cols = [col for col in feature_cols_severity if col not in df.columns]
if missing_cols:
    print(f"Error: Missing feature columns in DataFrame: {missing_cols}")
else:
    X_severity = df[feature_cols_severity]
    y_severity = df[target_col_severity]

    # Display the first few rows of X_severity and y_severity
    print("\nFirst few rows of X_severity (features for severity prediction):")
    display(X_severity.head())

    print("\nFirst few rows of y_severity (target: Flood Severity):")
    display(y_severity.head())

    # Display the data types of X_severity and y_severity
    print("\nData types of X_severity:")
    print(X_severity.dtypes)

    print("\nData types of y_severity:")
    print(y_severity.dtypes)


    # 3. Choose an appropriate model for this prediction task (Classification for severity categories)
    # RandomForestClassifier is suitable for multi-class classification
    model_severity = RandomForestClassifier(random_state=42)

    # 4. Split the data into training and testing sets
    X_train_severity, X_test_severity, y_train_severity, y_test_severity = train_test_split(X_severity, y_severity, test_size=0.3, random_state=42, stratify=y_severity) # Stratify to maintain severity distribution

    # 5. Train the chosen model using the training data
    model_severity.fit(X_train_severity, y_train_severity)

    # 6. Evaluate the performance of the trained model
    y_pred_severity = model_severity.predict(X_test_severity)

    # Calculate and print the accuracy
    accuracy_severity = accuracy_score(y_test_severity, y_pred_severity)
    print(f"\nFlood Severity Model Accuracy: {accuracy_severity:.4f}")

    # Calculate and print the classification report
    print("\nFlood Severity Model Classification Report:")
    print(classification_report(y_test_severity, y_pred_severity))

"""**Reasoning**:
The previous code still failed because the one-hot encoded columns for Municipality and Barangay were not correctly concatenated with the main DataFrame `df`. Although the dummy variables were created, they were not added as new columns to `df`, causing the KeyError when trying to select features. I need to concatenate the `municipality_dummies` and `barangay_dummies` DataFrames with `df` before selecting the features for the severity prediction model.


"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# 1. Define a new target variable for flood severity based on 'Water Level'
# Let's define severity levels:
# Low: Water Level <= 5 ft
# Medium: 5 ft < Water Level <= 15 ft
# High: Water Level > 15 ft
def categorize_severity(water_level):
    if water_level <= 5:
        return 'Low'
    elif 5 < water_level <= 15:
        return 'Medium'
    else:
        return 'High'

df['Flood_Severity'] = df['Water Level'].apply(categorize_severity)

# Display the distribution of the new target variable
print("Distribution of Flood Severity:")
print(df['Flood_Severity'].value_counts())

# Concatenate the municipality and barangay dummy variables to the main DataFrame
df = pd.concat([df, municipality_dummies, barangay_dummies], axis=1)


# 2. Select the features and the new target variable for severity
# We will use the same features as the refined model, excluding the old target and Water Level itself
feature_cols_severity = ['No. of Families affected', 'Damage Infrastructure', 'Damage Agriculture'] + list(month_dummies.columns) + list(municipality_dummies.columns) + list(barangay_dummies.columns)
target_col_severity = 'Flood_Severity'

# Ensure all feature columns exist in the DataFrame before selection
missing_cols = [col for col in feature_cols_severity if col not in df.columns]
if missing_cols:
    print(f"Error: Missing feature columns in DataFrame: {missing_cols}")
else:
    X_severity = df[feature_cols_severity]
    y_severity = df[target_col_severity]

    # Display the first few rows of X_severity and y_severity
    print("\nFirst few rows of X_severity (features for severity prediction):")
    display(X_severity.head())

    print("\nFirst few rows of y_severity (target: Flood Severity):")
    display(y_severity.head())

    # Display the data types of X_severity and y_severity
    print("\nData types of X_severity:")
    print(X_severity.dtypes)

    print("\nData types of y_severity:")
    print(y_severity.dtypes)


    # 3. Choose an appropriate model for this prediction task (Classification for severity categories)
    # RandomForestClassifier is suitable for multi-class classification
    model_severity = RandomForestClassifier(random_state=42)

    # 4. Split the data into training and testing sets
    X_train_severity, X_test_severity, y_train_severity, y_test_severity = train_test_split(X_severity, y_severity, test_size=0.3, random_state=42, stratify=y_severity) # Stratify to maintain severity distribution

    # 5. Train the chosen model using the training data
    model_severity.fit(X_train_severity, y_train_severity)

    # 6. Evaluate the performance of the trained model
    y_pred_severity = model_severity.predict(X_test_severity)

    # Calculate and print the accuracy
    accuracy_severity = accuracy_score(y_test_severity, y_pred_severity)
    print(f"\nFlood Severity Model Accuracy: {accuracy_severity:.4f}")

    # Calculate and print the classification report
    print("\nFlood Severity Model Classification Report:")
    print(classification_report(y_test_severity, y_pred_severity))

"""## Evaluate and interpret results

### Subtask:
Evaluate the performance of any new models and interpret the findings in the context of flood prediction and management.

**Reasoning**:
Analyze the classification report for the flood severity model, discuss the model's strengths and weaknesses, interpret the implications, and compare with the flood occurrence model to evaluate the performance and interpret findings.
"""

print("## Flood Severity Model Evaluation and Comparison")

print("\n### Analysis of the Flood Severity Model Classification Report:")
print("The classification report for the flood severity model provides a detailed breakdown of the model's performance for each severity level:")
print(classification_report(y_test_severity, y_pred_severity))

print("\n### Model Strengths and Weaknesses:")
print("- **Strengths:** The model demonstrates strong performance in predicting 'Low' flood severity, as indicated by high precision (1.00), recall (1.00), and f1-score (1.00). This is likely due to the large number of 'Low' severity instances in the dataset, which the model learned effectively.")
print("- **Weaknesses:** The model struggles significantly with predicting 'Medium' and 'High' flood severity.")
print("  - For 'High' severity, the precision, recall, and f1-score are all 0.00. This means the model did not correctly identify any 'High' severity events in the test set, and any predictions it made for 'High' were incorrect. This is likely a direct result of the very small number of 'High' severity instances in the dataset (imbalance).")
print("  - For 'Medium' severity, the precision is 1.00, but the recall is only 0.20, resulting in a low f1-score of 0.33. This indicates that while the model's predictions for 'Medium' are often correct when it makes them (high precision), it misses a large proportion of the actual 'Medium' severity events (low recall). This is also likely influenced by the data imbalance.")

print("\n### Implications for Flood Prediction and Management:")
print("- The model is currently reliable only for predicting low-severity flood events. While this can be useful for general awareness and minor preparedness, it is insufficient for managing and responding to more impactful floods.")
print("- The inability to predict 'Medium' and especially 'High' severity events effectively is a significant limitation for disaster management, where accurate warnings for severe events are critical for saving lives and minimizing damage.")
print("- Predicting 'Low' severity well might lead to complacency regarding the model's overall effectiveness if only accuracy is considered, masking its poor performance on critical high-impact events.")

print("\n### Comparison with the Flood Occurrence Model (Refined):")
print("- **Flood Occurrence Model (Refined):** This model predicts whether a flood will occur or not (binary classification). It achieved perfect accuracy (1.00) on the test set. Its potential use is for general flood warnings – indicating the likelihood of any flood occurring.")
print("- **Flood Severity Model:** This model predicts the level of flood severity (multi-class classification). It achieved an overall accuracy of 0.8298 but performed poorly on 'Medium' and 'High' severity classes due to data imbalance.")

print("\n### Respective Uses and Limitations:")
print("- **Flood Occurrence Model:** Useful for issuing broad flood alerts. Limitation: Does not provide information on the potential impact or required response level.")
print("- **Flood Severity Model:** Potentially more valuable as it indicates the scale of the flood. However, its current limitation is the inability to reliably predict higher severity levels due to data scarcity in those categories. Its use is currently limited to confirming low severity.")

print("\n### Next Steps Based on Evaluation:")
print("To improve the flood severity model and make it practically useful for disaster management, addressing the data imbalance for 'Medium' and 'High' severity levels is crucial. This could involve techniques like:")
print("- **Data Augmentation:** Synthesizing data for underrepresented classes (if feasible and representative).")
print("- **Resampling Techniques:** Oversampling the minority classes or undersampling the majority class.")
print("- **Algorithm Choice:** Exploring classification algorithms more robust to imbalanced datasets.")
print("- **Different Severity Thresholds:** Re-evaluating the severity categories and their thresholds based on domain expertise and data distribution.")

"""## Summary:

### Data Analysis Key Findings

*   The flood probability varies significantly across municipalities, with some municipalities having a higher likelihood of flood occurrence than others.
*   Including Municipality and Barangay features in the flood occurrence prediction model resulted in a perfect accuracy of 1.0000 on the test set.
*   When changing the prediction task to flood severity (categorized as Low, Medium, High based on Water Level), the dataset exhibits a significant imbalance, with 'Low' severity being the most frequent.
*   The flood severity prediction model achieved an overall accuracy of 0.8298 but performed poorly on predicting 'Medium' and 'High' severity levels due to data imbalance. The model showed perfect precision and recall for 'Low' severity, but 0.00 for 'High' severity and low recall (0.20) for 'Medium' severity.

### Insights or Next Steps

*   While the flood occurrence model is highly accurate, the flood severity model is currently limited in its ability to predict higher severity events due to data imbalance.
*   To improve the flood severity model's practical utility for disaster management, addressing the data imbalance for 'Medium' and 'High' severity levels is a crucial next step, potentially using techniques like resampling or exploring different algorithms.

# Task
Perform a time series prediction using SARIMA on the flood data.

## Prepare data for time series analysis

### Subtask:
Ensure the dataset has a proper time index and is in a suitable format for time series modeling. This may involve creating a datetime index and resampling the data if necessary.

**Reasoning**:
Combine Year, Month, and Day into a datetime index, handle remaining missing values in these columns using ffill, then resample the data to a daily frequency, and display the resulting time series DataFrame and its properties.
"""

# Combine 'Year', 'Month', and 'Day' columns into a single datetime column
# Handle remaining missing values using ffill for simplicity
df['Year'].fillna(method='ffill', inplace=True)
df['Month'].fillna(method='ffill', inplace=True)
df['Day'].fillna(method='ffill', inplace=True)

# Convert Year and Day to integer types for creating datetime objects
df['Year'] = df['Year'].astype(int)
df['Day'] = df['Day'].astype(int)

# Create a helper column for month number
month_map = {'JANUARY': 1, 'FEBRUARY': 2, 'MARCH': 3, 'APRIL': 4, 'MAY': 5, 'JUNE': 6,
             'JULY': 7, 'AUGUST': 8, 'SEPTEMBER': 9, 'OCTOBER': 10, 'NOVEMBER': 11, 'DECEMBER': 12, 'Unknown': 1} # Assign 1 for Unknown to avoid errors, though these dates might be less reliable


df['Month_Num'] = df['Month'].map(month_map)

# Create a datetime column
# Handle potential errors in date creation (e.g., invalid day for a month) by coercing to NaT
df['Date'] = pd.to_datetime(df[['Year', 'Month_Num', 'Day']], errors='coerce')

# Set the datetime column as the index
df.set_index('Date', inplace=True)

# Drop the helper 'Month_Num' and original date columns
df.drop(columns=['Year', 'Month', 'Day', 'Month_Num'], inplace=True)


# Resample the DataFrame to a daily frequency and aggregate 'Water Level'
# Use mean for aggregation
ts_df = df['Water Level'].resample('D').mean()

# Display the first few rows of the time series DataFrame
print("First few rows of the time series DataFrame:")
display(ts_df.head())

# Display the index and data types of the time series DataFrame
print("\nIndex of the time series DataFrame:")
print(ts_df.index)

print("\nData type of the time series DataFrame:")
print(ts_df.dtype)

"""**Reasoning**:
The previous code failed because the 'Month_Num' column was not correctly recognized when creating the datetime column. I need to ensure the 'Month_Num' column is correctly included in the DataFrame used to create the datetime objects. I will also address the FutureWarning by using the non-inplace fillna method.


"""

# Combine 'Year', 'Month', and 'Day' columns into a single datetime column
# Handle remaining missing values using ffill for simplicity
df['Year'] = df['Year'].fillna(method='ffill')
df['Month'] = df['Month'].fillna(method='ffill')
df['Day'] = df['Day'].fillna(method='ffill')

# Convert Year and Day to integer types for creating datetime objects
df['Year'] = df['Year'].astype(int)
df['Day'] = df['Day'].astype(int)

# Create a helper column for month number
month_map = {'JANUARY': 1, 'FEBRUARY': 2, 'MARCH': 3, 'APRIL': 4, 'MAY': 5, 'JUNE': 6,
             'JULY': 7, 'AUGUST': 8, 'SEPTEMBER': 9, 'OCTOBER': 10, 'NOVEMBER': 11, 'DECEMBER': 12, 'Unknown': 1} # Assign 1 for Unknown to avoid errors, though these dates might be less reliable

df['Month_Num'] = df['Month'].map(month_map)

# Create a temporary DataFrame with the necessary columns for to_datetime
temp_date_df = df[['Year', 'Month_Num', 'Day']].copy()
temp_date_df.rename(columns={'Month_Num': 'month'}, inplace=True) # Rename to 'month' for to_datetime

# Create a datetime column
# Handle potential errors in date creation (e.g., invalid day for a month) by coercing to NaT
df['Date'] = pd.to_datetime(temp_date_df, errors='coerce')

# Set the datetime column as the index
df.set_index('Date', inplace=True)

# Drop the helper 'Month_Num' and original date columns
df.drop(columns=['Year', 'Month', 'Day', 'Month_Num'], inplace=True)


# Resample the DataFrame to a daily frequency and aggregate 'Water Level'
# Use mean for aggregation
ts_df = df['Water Level'].resample('D').mean()

# Display the first few rows of the time series DataFrame
print("First few rows of the time series DataFrame:")
display(ts_df.head())

# Display the index and data types of the time series DataFrame
print("\nIndex of the time series DataFrame:")
print(ts_df.index)

print("\nData type of the time series DataFrame:")
print(ts_df.dtype)

"""## Explore time series patterns

### Subtask:
Visualize the time series data to identify trends, seasonality, or other patterns.

**Reasoning**:
Create a line plot of the time series data to visualize trends and patterns.
"""

import matplotlib.pyplot as plt

plt.figure(figsize=(15, 7))
plt.plot(ts_df)
plt.title('Daily Average Water Level Over Time')
plt.xlabel('Date')
plt.ylabel('Average Water Level')
plt.show()

"""## Check for stationarity

### Subtask:
Check for stationarity

**Reasoning**:
Perform the Augmented Dickey-Fuller test on the time series data to check for stationarity and apply differencing if necessary, then test for stationarity again.
"""

from statsmodels.tsa.stattools import adfuller

# Perform ADF test on the original time series
adf_result = adfuller(ts_df.dropna()) # Drop NaNs for the test
print("ADF Test Results on Original Time Series:")
print(f"ADF Statistic: {adf_result[0]:.4f}")
print(f"P-value: {adf_result[1]:.4f}")
print("Critical Values:")
for key, value in adf_result[4].items():
    print(f"   {key}: {value:.4f}")

# Check for stationarity based on p-value
if adf_result[1] > 0.05:
    print("\nThe time series is likely non-stationary. Applying first-order differencing.")
    # Apply first-order differencing
    ts_df_diff = ts_df.diff().dropna()

    # Print the first few values of the differenced time series
    print("\nFirst few values of the differenced time series:")
    display(ts_df_diff.head())

    # Plot the differenced time series
    plt.figure(figsize=(15, 7))
    plt.plot(ts_df_diff)
    plt.title('First-Order Differenced Daily Average Water Level Over Time')
    plt.xlabel('Date')
    plt.ylabel('Differenced Average Water Level')
    plt.show()

    # Perform ADF test again on the differenced time series
    adf_result_diff = adfuller(ts_df_diff)
    print("\nADF Test Results on Differenced Time Series:")
    print(f"ADF Statistic: {adf_result_diff[0]:.4f}")
    print(f"P-value: {adf_result_diff[1]:.4f}")
    print("Critical Values:")
    for key, value in adf_result_diff[4].items():
        print(f"   {key}: {value:.4f}")

    if adf_result_diff[1] <= 0.05:
        print("\nThe differenced time series is likely stationary.")
    else:
        print("\nThe differenced time series is still likely non-stationary.")

else:
    print("\nThe time series is likely stationary.")

"""**Reasoning**:
The previous code failed because the differenced time series `ts_df_diff` was empty after dropping NaNs, which caused an error in the second ADF test. This happened because the original time series `ts_df` likely contains a lot of NaNs, and differencing then dropping NaNs resulted in an empty Series. To fix this, I need to handle the NaNs in `ts_df` before differencing, possibly by filling them with a method appropriate for time series data, and then perform the differencing and the second ADF test.


"""

# Perform ADF test on the original time series
adf_result = adfuller(ts_df.dropna()) # Drop NaNs for the test
print("ADF Test Results on Original Time Series:")
print(f"ADF Statistic: {adf_result[0]:.4f}")
print(f"P-value: {adf_result[1]:.4f}")
print("Critical Values:")
for key, value in adf_result[4].items():
    print(f"   {key}: {value:.4f}")

# Check for stationarity based on p-value
if adf_result[1] > 0.05:
    print("\nThe time series is likely non-stationary. Applying first-order differencing.")
    # Handle NaNs before differencing, using forward fill as an example
    ts_df_filled = ts_df.fillna(method='ffill')
    # If there are still NaNs at the beginning, fill with backward fill
    ts_df_filled = ts_df_filled.fillna(method='bfill')


    # Apply first-order differencing and drop any resulting NaNs
    ts_df_diff = ts_df_filled.diff().dropna()

    # Print the first few values of the differenced time series
    print("\nFirst few values of the differenced time series:")
    display(ts_df_diff.head())

    # Plot the differenced time series
    plt.figure(figsize=(15, 7))
    plt.plot(ts_df_diff)
    plt.title('First-Order Differenced Daily Average Water Level Over Time')
    plt.xlabel('Date')
    plt.ylabel('Differenced Average Water Level')
    plt.show()

    # Perform ADF test again on the differenced time series
    if not ts_df_diff.empty:
        adf_result_diff = adfuller(ts_df_diff)
        print("\nADF Test Results on Differenced Time Series:")
        print(f"ADF Statistic: {adf_result_diff[0]:.4f}")
        print(f"P-value: {adf_result_diff[1]:.4f}")
        print("Critical Values:")
        for key, value in adf_result_diff[4].items():
            print(f"   {key}: {value:.4f}")

        if adf_result_diff[1] <= 0.05:
            print("\nThe differenced time series is likely stationary.")
        else:
            print("\nThe differenced time series is still likely non-stationary.")
    else:
        print("\nThe differenced time series is empty after handling NaNs and differencing.")

else:
    print("\nThe time series is likely stationary.")

"""## Identify sarima parameters

### Subtask:
Identify sarima parameters

**Reasoning**:
Generate and display the ACF and PACF plots for the stationary time series to identify potential SARIMA parameters (p, q, P, Q).
"""

from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# Generate and display the ACF plot
plt.figure(figsize=(12, 6))
plot_acf(ts_df_diff, lags=40, ax=plt.gca())
plt.title('Autocorrelation Function (ACF) of Differenced Water Level')
plt.xlabel('Lag')
plt.ylabel('Autocorrelation')
plt.show()

# Generate and display the PACF plot
plt.figure(figsize=(12, 6))
plot_pacf(ts_df_diff, lags=40, ax=plt.gca())
plt.title('Partial Autocorrelation Function (PACF) of Differenced Water Level')
plt.xlabel('Lag')
plt.ylabel('Partial Autocorrelation')
plt.show()

# Analyze the plots and suggest SARIMA parameters
print("\nAnalysis of ACF and PACF plots for SARIMA parameter identification:")
print("Non-seasonal parameters (p, q):")
print("- 'p' (AR order) is often suggested by the lag where the PACF cuts off.")
print("- 'q' (MA order) is often suggested by the lag where the ACF cuts off.")
print("Looking at the plots, the ACF and PACF show significant spikes at various lags, making the non-seasonal order determination challenging. There might be a mix of AR and MA components. Possible values for p and q could be explored in ranges like 0-2.")


print("\nSeasonal parameters (P, Q, s):")
print("- 's' (seasonal period) is likely 12 for monthly data, but the daily data resampling might obscure this. We can look for spikes at multiples of a potential seasonal period in the ACF/PACF.")
print("- 'P' (Seasonal AR order) is often suggested by the lag where the seasonal spikes in the PACF cut off.")
print("- 'Q' (Seasonal MA order) is often suggested by the lag where the seasonal spikes in the ACF cut off.")
print("For seasonal components, we should look for significant spikes at seasonal lags (e.g., multiples of a potential seasonal period). In the ACF, there might be significant spikes around lag 7, 14, 21, etc., and in the PACF around similar lags. This might suggest a weekly seasonality (s=7) or other patterns. The pattern isn't very clear for a strong annual seasonality (s=365 or s=12 if aggregated monthly). Let's consider both potential weekly (s=7) and annual (s=365) seasonality, or simply rely on the strongest observed seasonal lags.")
print("Possible values for P and Q could be explored in ranges like 0-1.")

print("\nSuggested SARIMA parameter ranges/values:")
print(f"- d: 1 (from first-order differencing)")
print(f"- D: 0 or 1 (depending on the need for seasonal differencing, not clearly indicated by plots)")
print(f"- s: Potentially 7 (weekly seasonality) or 365 (annual seasonality, though less clear) or 1 (no seasonal component)")
print(f"- p: Explore values like 0, 1, 2")
print(f"- q: Explore values like 0, 1, 2")
print(f"- P: Explore values like 0, 1 (at the suggested seasonal lag)")
print(f"- Q: Explore values like 0, 1 (at the suggested seasonal lag)")
print("\nA grid search approach testing various combinations of these parameters is recommended to find the best model.")

"""## Train sarima model

### Subtask:
Train sarima model

**Reasoning**:
Import the SARIMAX class, choose a set of SARIMA parameters based on the analysis of ACF/PACF plots and the stationarity test, instantiate the SARIMAX model with the chosen parameters and the filled time series data, fit the model, and print a summary of the fitted model.
"""

from statsmodels.tsa.statespace.sarimax import SARIMAX

# Choose SARIMA parameters based on previous analysis (example parameters)
# Non-seasonal order (p, d, q): p=1, d=1, q=1 (d=1 from differencing)
# Seasonal order (P, D, Q, s): P=1, D=0, Q=1, s=7 (assuming weekly seasonality)
# These are example parameters; a grid search would be needed for optimal values.
sarima_order = (1, 1, 1)
seasonal_order = (1, 0, 1, 7)

# Instantiate the SARIMAX model
# Use the filled time series data (ts_df_filled) to handle NaNs
model_sarima = SARIMAX(ts_df_filled, order=sarima_order, seasonal_order=seasonal_order)

# Fit the SARIMAX model to the data
results_sarima = model_sarima.fit()

# Print a summary of the fitted model
print(results_sarima.summary())

"""**Reasoning**:
The SARIMA model has been trained. The next step is to evaluate the trained model to assess its performance.


"""

# Evaluate the model (e.g., by looking at residual diagnostics or making predictions)
# For time series models, often evaluating on a hold-out set or looking at residuals is more informative than simple train/test split metrics on the whole series.
# Let's analyze the residuals to check if they are white noise.

# Plot residual diagnostics
results_sarima.plot_diagnostics(figsize=(15, 12))
plt.suptitle('SARIMA Model Diagnostics', y=1.02)
plt.tight_layout()
plt.show()

# The plot_diagnostics method provides several plots to check the residuals:
# 1. Standardized residual: Should look like white noise (no patterns, constant variance).
# 2. Histogram plus estimated density: Should approximate a normal distribution.
# 3. Normal QQ plot: Residuals quantiles vs. standard normal quantiles; should follow the straight line.
# 4. Correlogram (ACF of residuals): Should show no significant autocorrelation, especially at low lags.

# Additionally, we can check the Ljung-Box test p-value from the summary.
# A high p-value (e.g., > 0.05) indicates that the residuals are not distinguishable from white noise.
print("\nLjung-Box test p-value from model summary:")
print(results_sarima.summary().tables[1][5][1]) # Access the p-value for Ljung-Box (Q)

"""**Reasoning**:
The SARIMA model has been trained and evaluated through residual diagnostics. The next logical step is to use the trained model to make predictions on future time steps to forecast water levels.


"""

# Make predictions using the trained SARIMA model
# Predict future values
# Define the number of steps ahead to predict
steps_ahead = 30  # Example: Predict for the next 30 days

# Get the index for the future predictions
# We can use the last date in our time series and extend it for the number of steps ahead
last_date = ts_df_filled.index[-1]
future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=steps_ahead, freq='D')

# Make predictions
predictions = results_sarima.predict(start=future_dates[0], end=future_dates[-1])

# Print the predictions
print(f"\nSARIMA Model Predictions for the next {steps_ahead} days:")
print(predictions)

# Plot the original time series, the fitted values, and the predictions
plt.figure(figsize=(15, 7))
plt.plot(ts_df_filled.index, ts_df_filled, label='Original (Filled) Time Series')
plt.plot(results_sarima.fittedvalues.index, results_sarima.fittedvalues, color='green', label='Fitted Values')
plt.plot(predictions.index, predictions, color='red', label='Predictions')
plt.title('SARIMA Model Fit and Predictions')
plt.xlabel('Date')
plt.ylabel('Average Water Level')
plt.legend()
plt.show()

"""## Evaluate model performance

### Subtask:
Evaluate the performance of the SARIMA model using appropriate time series metrics (e.g., RMSE, MAE).

**Reasoning**:
Calculate and print the RMSE and MAE between the actual and fitted values of the SARIMA model to evaluate its performance using appropriate time series metrics.
"""

from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

# Calculate RMSE and MAE using the fitted values
# Note: fittedvalues are based on the training data
actual_values = ts_df_filled[results_sarima.fittedvalues.index]
fitted_values = results_sarima.fittedvalues

rmse = np.sqrt(mean_squared_error(actual_values, fitted_values))
mae = mean_absolute_error(actual_values, fitted_values)

print(f"SARIMA Model Performance on Training Data:")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")
print(f"Mean Absolute Error (MAE): {mae:.4f}")

"""## Visualize predictions

### Subtask:
Plot the historical data and the predicted values to visualize the model's performance and future forecasts.

**Reasoning**:
Plot the original time series, the fitted values, and the predictions to visualize the model's performance and future forecasts.
"""

import matplotlib.pyplot as plt

# 1. Create a figure and axes for the plot with a specified size.
plt.figure(figsize=(15, 7))

# 2. Plot the original time series data (ts_df_filled)
plt.plot(ts_df_filled.index, ts_df_filled, label='Original (Filled) Time Series')

# 3. Plot the fitted values from the SARIMA model (results_sarima.fittedvalues)
plt.plot(results_sarima.fittedvalues.index, results_sarima.fittedvalues, color='green', label='Fitted Values')

# 4. Plot the future predictions (predictions)
# Ensure the index of predictions is used for plotting
plt.plot(predictions.index, predictions, color='red', label='Predictions')

# 5. Add a title to the plot
plt.title('SARIMA Model Fit and Predictions')

# 6. Label the x-axis
plt.xlabel('Date')

# 7. Label the y-axis
plt.ylabel('Average Water Level')

# 8. Include a legend
plt.legend()

# 9. Display the plot
plt.show()

"""## Summary:

### Data Analysis Key Findings
* The initial time series data for 'Water Level' was found to be non-stationary based on the ADF test (p-value = 1.0000).
* After applying first-order differencing, the time series became stationary (ADF test p-value = 0.0000).
* Analysis of the ACF and PACF plots of the differenced series suggested potential non-seasonal parameters (p, q) in the range of 0-2 and seasonal parameters (P, Q) in the range of 0-1, with a potential weekly seasonality (s=7).
* A SARIMA model with parameters (1, 1, 1) for the non-seasonal part and (1, 0, 1, 7) for the seasonal part was trained.
* The Ljung-Box test on the model residuals resulted in a p-value of 0.1364, indicating that the residuals are statistically indistinguishable from white noise.
* The SARIMA model achieved an RMSE of 0.3748 and an MAE of 0.0204 on the training data (fitted values).

### Insights or Next Steps
* While the Ljung-Box test suggests the residuals are white noise, the visual residual diagnostics plots show some deviations from ideal conditions, indicating that the current SARIMA model might not fully capture all underlying patterns.
* A grid search approach exploring a wider range of SARIMA parameters (p, d, q, P, D, Q, s), including different seasonal periods (e.g., 365 for annual seasonality), should be performed to potentially find a model with better fit and diagnostic properties.

# Task
Refine SARIMA parameters, incorporate exogenous variables using SARIMAX, and compare SARIMA with Prophet for time series prediction of water levels.

## Refine sarima parameters

### Subtask:
Implement a method (e.g., grid search) to find more optimal parameters for the SARIMA model, aiming for improved accuracy.

**Reasoning**:
Implement a grid search to find optimal SARIMA parameters by iterating through a defined grid of parameters, fitting SARIMAX models, evaluating using AIC, and tracking the best parameters.
"""

import itertools
import warnings
from statsmodels.tsa.statespace.sarimax import SARIMAX

# 1. Define a grid of potential SARIMA parameters
# Non-seasonal orders (p, d, q)
p = d = q = range(0, 3) # Example range for non-seasonal parameters
non_seasonal_pdq = list(itertools.product(p, d, q))

# Seasonal orders (P, D, Q, s)
P = D = Q = range(0, 2) # Example range for seasonal parameters
s = [7] # Assuming weekly seasonality based on initial ACF/PACF observation

seasonal_pdq = [(x[0], x[1], x[2], s[0]) for x in list(itertools.product(P, D, Q))]

print('Examples of parameter combinations for SARIMA:')
print('SARIMA{}x{}'.format(non_seasonal_pdq[1], seasonal_pdq[1]))
print('SARIMA{}x{}'.format(non_seasonal_pdq[1][0:3], seasonal_pdq[1][0:4]))


# 2. Implement a loop to iterate through all combinations
warnings.filterwarnings("ignore") # Ignore convergence warnings

best_aic = float("inf")
best_pdq = None
best_seasonal_pdq = None

print("\nPerforming Grid Search for Optimal SARIMA Parameters...")

for param in non_seasonal_pdq:
    for param_seasonal in seasonal_pdq:
        try:
            # 3. Fit a SARIMAX model for each combination
            model = SARIMAX(ts_df_filled,
                            order=param,
                            seasonal_order=param_seasonal,
                            enforce_stationarity=False,
                            enforce_invertibility=False)

            results = model.fit()

            # 4. Calculate an evaluation metric (AIC)
            if results.aic < best_aic:
                best_aic = results.aic
                best_pdq = param
                best_seasonal_pdq = param_seasonal

        except Exception as e:
            # Handle potential errors during fitting
            # print(f"Error fitting SARIMA model with parameters {param}x{param_seasonal}: {e}")
            continue

# 6. Identify the optimal non-seasonal and seasonal orders
# 7. Print the optimal SARIMA parameters found
print("\nGrid Search Complete.")
print(f"Optimal SARIMA Parameters: SARIMA({best_pdq[0]},{best_pdq[1]},{best_pdq[2]})x({best_seasonal_pdq[0]},{best_seasonal_pdq[1]},{best_seasonal_pdq[2]},{best_seasonal_pdq[3]})")
print(f"Best AIC: {best_aic:.4f}")

"""## Evaluate and compare models

### Subtask:
Evaluate the performance of the refined SARIMA, SARIMAX (if applicable), and Prophet models using appropriate time series metrics and compare their results.

**Reasoning**:
Generate predictions from the Prophet model on the historical data, calculate evaluation metrics (RMSE, MAE) for the Prophet model, and then compare the performance metrics of all three models (Optimal SARIMA, SARIMAX, Prophet) to determine the best-performing model.
"""

# Make predictions on the historical data using the Prophet model for evaluation
forecast_prophet = model_prophet.predict(prophet_df[['ds']])

# Align Prophet's forecast with the original time series index for evaluation
# Prophet's forecast includes trend, seasonality, etc., and the 'yhat' column is the prediction
prophet_fitted_values = forecast_prophet.set_index('ds')['yhat'].reindex(ts_df_filled.index)

# Calculate RMSE and MAE for the Prophet model on the historical data
rmse_prophet = np.sqrt(mean_squared_error(ts_df_filled, prophet_fitted_values))
mae_prophet = mean_absolute_error(ts_df_filled, prophet_fitted_values)

print("\nProphet Model Performance on Historical Data:")
print(f"Root Mean Squared Error (RMSE): {rmse_prophet:.4f}")
print(f"Mean Absolute Error (MAE): {mae_prophet:.4f}")

print("\n--- Model Comparison ---")
print("Model                 | RMSE     | MAE")
print("----------------------|----------|----------")
print(f"Optimal SARIMA        | {rmse_optimal:.4f} | {mae_optimal:.4f}")
print(f"SARIMAX (with Exog)   | {rmse_sarimax:.4f} | {mae_sarimax:.4f}")
print(f"Prophet               | {rmse_prophet:.4f} | {mae_prophet:.4f}")

# Determine the best performing model based on RMSE (lower is better)
best_model_name = ""
best_rmse = float("inf")

if rmse_optimal < best_rmse:
    best_rmse = rmse_optimal
    best_model_name = "Optimal SARIMA"

if rmse_sarimax < best_rmse:
    best_rmse = rmse_sarimax
    best_model_name = "SARIMAX (with Exog)"

if rmse_prophet < best_rmse:
    best_rmse = rmse_prophet
    best_model_name = "Prophet"

print(f"\nBased on RMSE on historical data, the best performing model is: {best_model_name}")

# You can also consider MAE for comparison.

"""## Visualize forecasts

### Subtask:
Visualize the forecasts from the best-performing model(s) along with historical data.

**Reasoning**:
Visualize the historical data and the forecasts from the best-performing model(s) to show their fit and future predictions.
"""

# Make future predictions using the best performing model
# For Prophet, we already have the 'future_prophet' DataFrame

if best_model_name == "Optimal SARIMA":
    # Make predictions using Optimal SARIMA
    last_date_sarima = ts_df_filled.index[-1]
    future_dates_sarima = pd.date_range(start=last_date_sarima + pd.Timedelta(days=1), periods=30, freq='D')
    future_forecast = results_sarima_optimal.predict(start=future_dates_sarima[0], end=future_dates_sarima[-1])
    model_title = "Optimal SARIMA Model Forecast"

elif best_model_name == "SARIMAX (with Exog)":
    # To make future predictions with SARIMAX, we need future values for exogenous variables.
    # As we don't have actual future exogenous data, we'll use the last known values as a simple forward fill.
    # In a real-world scenario, you would need forecasted exogenous variables.
    last_exog_values = exog_data.iloc[-1].values.reshape(1, -1)
    future_exog_data = pd.DataFrame(np.repeat(last_exog_values, 30, axis=0), index=pd.date_range(start=ts_df_filled.index[-1] + pd.Timedelta(days=1), periods=30, freq='D'), columns=exog_data.columns)

    last_date_sarimax = ts_df_filled.index[-1]
    future_dates_sarimax = pd.date_range(start=last_date_sarimax + pd.Timedelta(days=1), periods=30, freq='D')

    future_forecast = results_sarimax.predict(start=future_dates_sarimax[0], end=future_dates_sarimax[-1], exog=future_exog_data)
    model_title = "SARIMAX Model Forecast (with Exog)"


elif best_model_name == "Prophet":
    # Prophet's predict method directly provides future forecasts
    future_forecast_prophet = model_prophet.predict(future_prophet)
    future_forecast = future_forecast_prophet.set_index('ds')['yhat']
    model_title = "Prophet Model Forecast"


# Visualize the historical data and the future forecast
plt.figure(figsize=(15, 7))
plt.plot(ts_df_filled.index, ts_df_filled, label='Historical Data')
plt.plot(future_forecast.index, future_forecast, color='red', label='Future Forecast')
plt.title(model_title)
plt.xlabel('Date')
plt.ylabel('Average Water Level')
plt.legend()
plt.show()

# Optional: Visualize the fitted values of the best model on historical data
# if best_model_name == "Optimal SARIMA":
#     plt.figure(figsize=(15, 7))
#     plt.plot(ts_df_filled.index, ts_df_filled, label='Historical Data')
#     plt.plot(results_sarima_optimal.fittedvalues.index, results_sarima_optimal.fittedvalues, color='green', label='Fitted Values (Optimal SARIMA)')
#     plt.title('Optimal SARIMA Model Fit on Historical Data')
#     plt.xlabel('Date')
#     plt.ylabel('Average Water Level')
#     plt.legend()
#     plt.show()
# elif best_model_name == "SARIMAX (with Exog)":
#      plt.figure(figsize=(15, 7))
#      plt.plot(ts_df_filled.index, ts_df_filled, label='Historical Data')
#      plt.plot(results_sarimax.fittedvalues.index, results_sarimax.fittedvalues, color='orange', label='Fitted Values (SARIMAX)')
#      plt.title('SARIMAX Model Fit on Historical Data')
#      plt.xlabel('Date')
#      plt.ylabel('Average Water Level')
#      plt.legend()
#      plt.show()
# elif best_model_name == "Prophet":
#      plt.figure(figsize=(15, 7))
#      plt.plot(ts_df_filled.index, ts_df_filled, label='Historical Data')
#      plt.plot(prophet_fitted_values.index, prophet_fitted_values, color='purple', label='Fitted Values (Prophet)')
#      plt.title('Prophet Model Fit on Historical Data')
#      plt.xlabel('Date')
#      plt.ylabel('Average Water Level')
#      plt.legend()
#      plt.show()

"""## Summary:

### Data Analysis Key Findings
* The optimal SARIMA model was identified with parameters (0, 1, 0)x(0, 0, 0, 7) based on a grid search minimizing AIC.
* The SARIMAX model incorporating exogenous variables ('No. of Families affected', 'Damage Infrastructure', 'Damage Agriculture') with the optimal SARIMA parameters was trained.
* A Prophet model was trained on the time series data.
* Comparing the models based on RMSE and MAE on historical data:
    * Optimal SARIMA: RMSE = {{rmse_optimal:.4f}}, MAE = {{mae_optimal:.4f}}
    * SARIMAX (with Exog): RMSE = {{rmse_sarimax:.4f}}, MAE = {{mae_sarimax:.4f}}
    * Prophet: RMSE = {{rmse_prophet:.4f}}, MAE = {{mae_prophet:.4f}}
* The SARIMAX model with exogenous variables achieved the lowest RMSE and MAE on the historical data among the three models compared.

### Insights or Next Steps
* The inclusion of exogenous variables in the SARIMAX model appears to have improved the model's fit to the historical data compared to the SARIMA model alone.
* The Prophet model also provides a reasonable fit, but in this comparison, SARIMAX with exogenous variables performed best based on the chosen metrics on historical data.
* To get a more robust comparison, it would be beneficial to evaluate the models on a held-out test set of future data (if available) or use time series cross-validation.
* Further refinement of the Prophet model (e.g., adding seasonality, holidays, or trend changepoints) or exploring different exogenous variables for SARIMAX could potentially lead to even better forecasting accuracy.
* The forecasts from the best-performing model can be used to inform flood preparedness and response strategies.

## Visualize SARIMAX Forecasts

### Subtask:
Visualize the historical data, fitted values, and future forecasts from the SARIMAX model.

**Reasoning**:
Plot the original time series, the fitted values from the SARIMAX model, and the future predictions from the SARIMAX model to visualize its performance and forecast.
"""

import matplotlib.pyplot as plt

# Ensure results_sarimax and exog_data are available from previous steps
# You might need to rerun previous cells if the kernel state was reset

# Define the number of steps ahead to predict
steps_ahead_sarimax = 30 # Example: Predict for the next 30 days

# Create future exogenous data (using forward fill of the last known values)
last_exog_values = exog_data.iloc[-1].values.reshape(1, -1)
future_exog_data_sarimax = pd.DataFrame(np.repeat(last_exog_values, steps_ahead_sarimax, axis=0),
                                        index=pd.date_range(start=ts_df_filled.index[-1] + pd.Timedelta(days=1), periods=steps_ahead_sarimax, freq='D'),
                                        columns=exog_data.columns)

# Make future predictions using the trained SARIMAX model
last_date_sarimax = ts_df_filled.index[-1]
future_dates_sarimax = pd.date_range(start=last_date_sarimax + pd.Timedelta(days=1), periods=steps_ahead_sarimax, freq='D')

future_forecast_sarimax = results_sarimax.predict(start=future_dates_sarimax[0], end=future_dates_sarimax[-1], exog=future_exog_data_sarimax)


# Visualize the historical data, fitted values, and future forecast from SARIMAX
plt.figure(figsize=(15, 7))
plt.plot(ts_df_filled.index, ts_df_filled, label='Historical Data')
plt.plot(results_sarimax.fittedvalues.index, results_sarimax.fittedvalues, color='orange', label='SARIMAX Fitted Values')
plt.plot(future_forecast_sarimax.index, future_forecast_sarimax, color='red', label='SARIMAX Future Forecast')

plt.title('SARIMAX Model Fit and Forecast')
plt.xlabel('Date')
plt.ylabel('Average Water Level')
plt.legend()
plt.show()

"""## Evaluate and compare models

### Subtask:
Evaluate the performance of the refined SARIMA, SARIMAX (if applicable), and Prophet models using appropriate time series metrics and compare their results.

**Reasoning**:
Generate predictions from the Prophet model on the historical data, calculate evaluation metrics (RMSE, MAE) for the Prophet model, and then compare the performance metrics of all three models (Optimal SARIMA, SARIMAX, Prophet) to determine the best-performing model.
"""

# Make predictions on the historical data using the Prophet model for evaluation
forecast_prophet = model_prophet.predict(prophet_df[['ds']])

# Align Prophet's forecast with the original time series index for evaluation
# Prophet's forecast includes trend, seasonality, etc., and the 'yhat' column is the prediction
prophet_fitted_values = forecast_prophet.set_index('ds')['yhat'].reindex(ts_df_filled.index)

# Calculate RMSE and MAE for the Prophet model on the historical data
rmse_prophet = np.sqrt(mean_squared_error(ts_df_filled, prophet_fitted_values))
mae_prophet = mean_absolute_error(ts_df_filled, prophet_fitted_values)

print("\nProphet Model Performance on Historical Data:")
print(f"Root Mean Squared Error (RMSE): {rmse_prophet:.4f}")
print(f"Mean Absolute Error (MAE): {mae_prophet:.4f}")

print("\n--- Model Comparison ---")
print("Model                 | RMSE     | MAE")
print("----------------------|----------|----------")
print(f"Optimal SARIMA        | {rmse_optimal:.4f} | {mae_optimal:.4f}")
print(f"SARIMAX (with Exog)   | {rmse_sarimax:.4f} | {mae_sarimax:.4f}")
print(f"Prophet               | {rmse_prophet:.4f} | {mae_prophet:.4f}")

# Determine the best performing model based on RMSE (lower is better)
best_model_name = ""
best_rmse = float("inf")

if rmse_optimal < best_rmse:
    best_rmse = rmse_optimal
    best_model_name = "Optimal SARIMA"

if rmse_sarimax < best_rmse:
    best_rmse = rmse_sarimax
    best_model_name = "SARIMAX (with Exog)"

if rmse_prophet < best_rmse:
    best_rmse = rmse_prophet
    best_model_name = "Prophet"

print(f"\nBased on RMSE on historical data, the best performing model is: {best_model_name}")

# You can also consider MAE for comparison.

"""## Visualize forecasts

### Subtask:
Visualize the forecasts from the best-performing model(s) along with historical data.

**Reasoning**:
Visualize the historical data and the forecasts from the best-performing model(s) to show their fit and future predictions.
"""

# Make future predictions using the best performing model
# For Prophet, we already have the 'future_prophet' DataFrame

if best_model_name == "Optimal SARIMA":
    # Make predictions using Optimal SARIMA
    last_date_sarima = ts_df_filled.index[-1]
    future_dates_sarima = pd.date_range(start=last_date_sarima + pd.Timedelta(days=1), periods=30, freq='D')
    future_forecast = results_sarima_optimal.predict(start=future_dates_sarima[0], end=future_dates_sarima[-1])
    model_title = "Optimal SARIMA Model Forecast"

elif best_model_name == "SARIMAX (with Exog)":
    # To make future predictions with SARIMAX, we need future values for exogenous variables.
    # As we don't have actual future exogenous data, we'll use the last known values as a simple forward fill.
    # In a real-world scenario, you would need forecasted exogenous variables.
    last_exog_values = exog_data.iloc[-1].values.reshape(1, -1)
    future_exog_data = pd.DataFrame(np.repeat(last_exog_values, 30, axis=0), index=pd.date_range(start=ts_df_filled.index[-1] + pd.Timedelta(days=1), periods=30, freq='D'), columns=exog_data.columns)

    last_date_sarimax = ts_df_filled.index[-1]
    future_dates_sarimax = pd.date_range(start=last_date_sarimax + pd.Timedelta(days=1), periods=30, freq='D')

    future_forecast = results_sarimax.predict(start=future_dates_sarimax[0], end=future_dates_sarimax[-1], exog=future_exog_data)
    model_title = "SARIMAX Model Forecast (with Exog)"


elif best_model_name == "Prophet":
    # Prophet's predict method directly provides future forecasts
    future_forecast_prophet = model_prophet.predict(future_prophet)
    future_forecast = future_forecast_prophet.set_index('ds')['yhat']
    model_title = "Prophet Model Forecast"


# Visualize the historical data and the future forecast
plt.figure(figsize=(15, 7))
plt.plot(ts_df_filled.index, ts_df_filled, label='Historical Data')
plt.plot(future_forecast.index, future_forecast, color='red', label='Future Forecast')
plt.title(model_title)
plt.xlabel('Date')
plt.ylabel('Average Water Level')
plt.legend()
plt.show()

# Optional: Visualize the fitted values of the best model on historical data
# if best_model_name == "Optimal SARIMA":
#     plt.figure(figsize=(15, 7))
#     plt.plot(ts_df_filled.index, ts_df_filled, label='Historical Data')
#     plt.plot(results_sarima_optimal.fittedvalues.index, results_sarima_optimal.fittedvalues, color='green', label='Fitted Values (Optimal SARIMA)')
#     plt.title('Optimal SARIMA Model Fit on Historical Data')
#     plt.xlabel('Date')
#     plt.ylabel('Average Water Level')
#     plt.legend()
#     plt.show()
# elif best_model_name == "SARIMAX (with Exog)":
#      plt.figure(figsize=(15, 7))
#      plt.plot(ts_df_filled.index, ts_df_filled, label='Historical Data')
#      plt.plot(results_sarimax.fittedvalues.index, results_sarimax.fittedvalues, color='orange', label='Fitted Values (SARIMAX)')
#      plt.title('SARIMAX Model Fit on Historical Data')
#      plt.xlabel('Date')
#      plt.ylabel('Average Water Level')
#      plt.legend()
#      plt.show()
# elif best_model_name == "Prophet":
#      plt.figure(figsize=(15, 7))
#      plt.plot(ts_df_filled.index, ts_df_filled, label='Historical Data')
#      plt.plot(prophet_fitted_values.index, prophet_fitted_values, color='purple', label='Fitted Values (Prophet)')
#      plt.title('Prophet Model Fit on Historical Data')
#      plt.xlabel('Date')
#      plt.ylabel('Average Water Level')
#      plt.legend()
#      plt.show()

"""## Summary:

### Data Analysis Key Findings
* The optimal SARIMA model was identified with parameters (0, 1, 0)x(0, 0, 0, 7) based on a grid search minimizing AIC.
* The SARIMAX model incorporating exogenous variables ('No. of Families affected', 'Damage Infrastructure', 'Damage Agriculture') with the optimal SARIMA parameters was trained.
* A Prophet model was trained on the time series data.
* Comparing the models based on RMSE and MAE on historical data:
    * Optimal SARIMA: RMSE = {{rmse_optimal:.4f}}, MAE = {{mae_optimal:.4f}}
    * SARIMAX (with Exog): RMSE = {{rmse_sarimax:.4f}}, MAE = {{mae_sarimax:.4f}}
    * Prophet: RMSE = {{rmse_prophet:.4f}}, MAE = {{mae_prophet:.4f}}
* The SARIMAX model with exogenous variables achieved the lowest RMSE and MAE on the historical data among the three models compared.

### Insights or Next Steps
* The inclusion of exogenous variables in the SARIMAX model appears to have improved the model's fit to the historical data compared to the SARIMA model alone.
* The Prophet model also provides a reasonable fit, but in this comparison, SARIMAX with exogenous variables performed best based on the chosen metrics on historical data.
* To get a more robust comparison, it would be beneficial to evaluate the models on a held-out test set of future data (if available) or use time series cross-validation.
* Further refinement of the Prophet model (e.g., adding seasonality, holidays, or trend changepoints) or exploring different exogenous variables for SARIMAX could potentially lead to even better forecasting accuracy.
* The forecasts from the best-performing model can be used to inform flood preparedness and response strategies.

## Train Prophet model

### Subtask:
Train a Prophet model on the time series data for comparison with the SARIMA/SARIMAX models.

**Reasoning**:
Prepare the time series data in the format required by Prophet (DataFrame with 'ds' and 'y' columns), instantiate and fit the Prophet model, and create a future DataFrame for predictions.
"""

from prophet import Prophet

# Prepare data for Prophet: Create a DataFrame with 'ds' (datetime) and 'y' (water level) columns
prophet_df = ts_df_filled.reset_index()
prophet_df.rename(columns={'Date': 'ds', 'Water Level': 'y'}, inplace=True)

# Instantiate and fit the Prophet model
model_prophet = Prophet()
model_prophet.fit(prophet_df)

# Create a future DataFrame for predictions (e.g., for the next 30 days)
future_prophet = model_prophet.make_future_dataframe(periods=30)

# Display the first few rows of the future DataFrame
print("First few rows of the future DataFrame for Prophet predictions:")
display(future_prophet.head())

print("\nProphet model training complete.")

"""**Reasoning**:
The SARIMAX model with exogenous variables has been trained. The next step is to evaluate the performance of this model and compare it to the optimal SARIMA model without exogenous variables. Then, I will proceed with training and evaluating a Prophet model as part of the overall task.
"""

# Evaluate the SARIMAX model with exogenous variables
# Calculate RMSE and MAE using the fitted values
actual_values_sarimax = ts_df_filled[results_sarimax.fittedvalues.index]
fitted_values_sarimax = results_sarimax.fittedvalues

rmse_sarimax = np.sqrt(mean_squared_error(actual_values_sarimax, fitted_values_sarimax))
mae_sarimax = mean_absolute_error(actual_values_sarimax, fitted_values_sarimax)

print("\nSARIMAX Model Performance (with Exogenous Variables) on Training Data:")
print(f"Root Mean Squared Error (RMSE): {rmse_sarimax:.4f}")
print(f"Mean Absolute Error (MAE): {mae_sarimax:.4f}")

# Compare with the optimal SARIMA model performance
print("\nComparison with Optimal SARIMA Model (without Exogenous Variables):")
print(f"Optimal SARIMA RMSE: {rmse_optimal:.4f}")
print(f"Optimal SARIMA MAE: {mae_optimal:.4f}")

# Visualize the fitted values of the SARIMAX model against the original time series
plt.figure(figsize=(15, 7))
plt.plot(ts_df_filled.index, ts_df_filled, label='Original (Filled) Time Series')
plt.plot(results_sarimax.fittedvalues.index, results_sarimax.fittedvalues, color='orange', label='SARIMAX Fitted Values')
plt.title('SARIMAX Model Fit vs. Original Time Series')
plt.xlabel('Date')
plt.ylabel('Average Water Level')
plt.legend()
plt.show()

# Plot residual diagnostics for the SARIMAX model
results_sarimax.plot_diagnostics(figsize=(15, 12))
plt.suptitle('SARIMAX Model Diagnostics (with Exogenous Variables)', y=1.02)
plt.tight_layout()
plt.show()

# Print the Ljung-Box test p-value from the SARIMAX model summary
try:
    ljung_box_pvalue_sarimax = results_sarimax.summary().tables[0].data[5][1]
    print("\nLjung-Box test p-value from SARIMAX model summary:")
    print(ljung_box_pvalue_sarimax)
except Exception as e:
    print(f"\nCould not retrieve Ljung-Box p-value from SARIMAX summary: {e}")
    print("Please manually inspect the SARIMAX summary table to find the Ljung-Box p-value.")

# Next: Prepare data and train Prophet model

"""**Reasoning**:
The optimal SARIMA parameters have been identified through the grid search. The next logical step is to train the SARIMA model using these optimal parameters.
"""

# Train the SARIMA model using the optimal parameters found
optimal_sarima_order = best_pdq
optimal_seasonal_order = best_seasonal_pdq

print(f"Training SARIMA model with optimal parameters: SARIMA{optimal_sarima_order}x{optimal_seasonal_order}")

# Instantiate the SARIMAX model with optimal parameters
model_sarima_optimal = SARIMAX(ts_df_filled,
                               order=optimal_sarima_order,
                               seasonal_order=optimal_seasonal_order,
                               enforce_stationarity=False,
                               enforce_invertibility=False)

# Fit the SARIMAX model to the data
results_sarima_optimal = model_sarima_optimal.fit()

# Print a summary of the fitted optimal model
print("\nSummary of the Optimal SARIMA Model:")
print(results_sarima_optimal.summary())

"""## Prepare exogenous variables for SARIMAX

### Subtask:
Identify and prepare potential exogenous variables from the dataset for inclusion in the SARIMAX model.

**Reasoning**:
Identify potential exogenous variables from the original DataFrame that could influence the water level time series, align them with the time series index by resampling and filling missing values, and display the prepared exogenous data and its data types.
"""

# Identify potential exogenous variables from the original DataFrame (df)
# Exogenous variables should be external factors that might influence water level but are not directly part of the time series being modeled.
# From the available columns, 'No. of Families affected', 'Damage Infrastructure', and 'Damage Agriculture' could potentially be related to events that also cause changes in water level.
# We need to ensure these are aligned with the time series index.

# Select potential exogenous variables. Exclude 'Water Level' itself and date-related columns.
exog_cols = ['No. of Families affected', 'Damage Infrastructure', 'Damage Agriculture']

# Create the exogenous variables DataFrame, aligned by the time series index
exog_data = df[exog_cols].resample('D').mean() # Resample to daily and take the mean if multiple entries per day

# Fill any resulting NaNs in the exogenous data, using ffill and bfill as done for the time series
exog_data = exog_data.fillna(method='ffill')
exog_data = exog_data.fillna(method='bfill')

# Ensure the exogenous data index matches the time series index
if not exog_data.index.equals(ts_df_filled.index):
    print("\nWarning: Exogenous data index does not match time series index. Aligning indices.")
    # Align the exogenous data index with the time series index
    exog_data = exog_data.reindex(ts_df_filled.index)
    # Fill any new NaNs introduced by reindexing if necessary (e.g., if exogenous data starts later)
    exog_data = exog_data.fillna(method='ffill')
    exog_data = exog_data.fillna(method='bfill')


print("\nPrepared Exogenous Variables (first 5 rows):")
display(exog_data.head())
print("\nExogenous Variables Data Types:")
print(exog_data.dtypes)

"""**Reasoning**:
The optimal SARIMA parameters have been identified through the grid search. The next logical step is to train the SARIMA model using these optimal parameters.


"""

# Train the SARIMA model using the optimal parameters found
optimal_sarima_order = best_pdq
optimal_seasonal_order = best_seasonal_pdq

print(f"Training SARIMA model with optimal parameters: SARIMA{optimal_sarima_order}x{optimal_seasonal_order}")

# Instantiate the SARIMAX model with optimal parameters
model_sarima_optimal = SARIMAX(ts_df_filled,
                               order=optimal_sarima_order,
                               seasonal_order=optimal_seasonal_order,
                               enforce_stationarity=False,
                               enforce_invertibility=False)

# Fit the SARIMAX model to the data
results_sarima_optimal = model_sarima_optimal.fit()

# Print a summary of the fitted optimal model
print("\nSummary of the Optimal SARIMA Model:")
print(results_sarima_optimal.summary())

"""**Reasoning**:
The optimal SARIMA model has been trained. The next step is to evaluate the performance of this optimal model using appropriate time series metrics and visualize the results, similar to the previous evaluation step but now with the best model.


"""

# Evaluate the performance of the optimal SARIMA model
# Calculate RMSE and MAE using the fitted values from the optimal model
actual_values_optimal = ts_df_filled[results_sarima_optimal.fittedvalues.index]
fitted_values_optimal = results_sarima_optimal.fittedvalues

rmse_optimal = np.sqrt(mean_squared_error(actual_values_optimal, fitted_values_optimal))
mae_optimal = mean_absolute_error(actual_values_optimal, fitted_values_optimal)

print(f"Optimal SARIMA Model Performance on Training Data:")
print(f"Root Mean Squared Error (RMSE): {rmse_optimal:.4f}")
print(f"Mean Absolute Error (MAE): {mae_optimal:.4f}")

# Visualize the fitted values of the optimal model against the original time series
plt.figure(figsize=(15, 7))
plt.plot(ts_df_filled.index, ts_df_filled, label='Original (Filled) Time Series')
plt.plot(results_sarima_optimal.fittedvalues.index, results_sarima_optimal.fittedvalues, color='green', label='Optimal SARIMA Fitted Values')
plt.title('Optimal SARIMA Model Fit vs. Original Time Series')
plt.xlabel('Date')
plt.ylabel('Average Water Level')
plt.legend()
plt.show()

# Plot residual diagnostics for the optimal model
results_sarima_optimal.plot_diagnostics(figsize=(15, 12))
plt.suptitle('Optimal SARIMA Model Diagnostics', y=1.02)
plt.tight_layout()
plt.show()

# Print the Ljung-Box test p-value from the optimal model summary
try:
    # Access the Ljung-Box (L1) p-value from the summary table
    # Based on the previous summary output, it seems to be in the first table (index 0), row related to Ljung-Box, second column (p-value).
    # The row for Ljung-Box (L1) seems to be at index 5 in the first table.
    ljung_box_pvalue = results_sarima_optimal.summary().tables[0].data[5][2] # Corrected index for p-value

    print("\nLjung-Box test p-value from optimal model summary:")
    print(ljung_box_pvalue)
except Exception as e:
    print(f"\nCould not retrieve Ljung-Box p-value from summary: {e}")
    print("Please manually inspect the summary table to find the Ljung-Box p-value.")

"""**Reasoning**:
The previous code failed because the index used to access the Ljung-Box p-value in the summary table was incorrect for the optimal model's summary output. I need to correct the indexing to accurately retrieve the Ljung-Box p-value from the summary table and then proceed with the next step of incorporating exogenous variables, as outlined in the main task.


"""

# Corrected: Print the Ljung-Box test p-value from the optimal model summary
# Access the Ljung-Box (L1) p-value from the summary table
# The exact index might vary slightly, so we can try to locate it or use a more robust method if needed.
# Based on the previous summary output, it seems to be in the first table (index 0), row related to Ljung-Box, second column (p-value).
# Let's re-examine the summary structure or try a common index.
# Looking at the previous summary, Ljung-Box (L1) is in the first table (index 0), and the p-value is the second item in that row.
# The row for Ljung-Box (L1) seems to be at index 5.

try:
    ljung_box_pvalue = results_sarima_optimal.summary().tables[0].data[5][1]
    print("\nLjung-Box test p-value from optimal model summary:")
    print(ljung_box_pvalue)
except Exception as e:
    print(f"\nCould not retrieve Ljung-Box p-value from summary: {e}")
    print("Please manually inspect the summary table to find the Ljung-Box p-value.")


# Now, proceed with incorporating exogenous variables as per the main task.
# Identify potential exogenous variables from the original DataFrame (df)
# Exogenous variables should be external factors that might influence water level but are not directly part of the time series being modeled.
# From the available columns, 'No. of Families affected', 'Damage Infrastructure', and 'Damage Agriculture' could potentially be related to events that also cause changes in water level.
# We need to ensure these are aligned with the time series index.

# Select potential exogenous variables. Exclude 'Water Level' itself and date-related columns.
exog_cols = ['No. of Families affected', 'Damage Infrastructure', 'Damage Agriculture']

# Create the exogenous variables DataFrame, aligned by the time series index
exog_data = df[exog_cols].resample('D').mean() # Resample to daily and take the mean if multiple entries per day

# Fill any resulting NaNs in the exogenous data, using ffill and bfill as done for the time series
exog_data = exog_data.fillna(method='ffill')
exog_data = exog_data.fillna(method='bfill')

# Ensure the exogenous data index matches the time series index
if not exog_data.index.equals(ts_df_filled.index):
    print("\nWarning: Exogenous data index does not match time series index. Aligning indices.")
    # Align the exogenous data index with the time series index
    exog_data = exog_data.reindex(ts_df_filled.index)
    # Fill any new NaNs introduced by reindexing if necessary (e.g., if exogenous data starts later)
    exog_data = exog_data.fillna(method='ffill')
    exog_data = exog_data.fillna(method='bfill')


print("\nPrepared Exogenous Variables (first 5 rows):")
display(exog_data.head())
print("\nExogenous Variables Data Types:")
print(exog_data.dtypes)

# Now, train a SARIMAX model with the optimal SARIMA parameters and the exogenous variables
print("\nTraining SARIMAX model with optimal SARIMA parameters and exogenous variables...")

try:
    model_sarimax = SARIMAX(ts_df_filled,
                            exog=exog_data, # Include exogenous variables
                            order=optimal_sarima_order,
                            seasonal_order=optimal_seasonal_order,
                            enforce_stationarity=False,
                            enforce_invertibility=False)

    results_sarimax = model_sarimax.fit()

    # Print a summary of the fitted SARIMAX model
    print("\nSummary of the SARIMAX Model with Exogenous Variables:")
    print(results_sarimax.summary())

except Exception as e:
    print(f"\nError training SARIMAX model with exogenous variables: {e}")
    results_sarimax = None # Set to None if fitting fails for later checks

"""**Reasoning**:
The SARIMAX model with exogenous variables has been trained. The next step is to evaluate the performance of this model and compare it to the optimal SARIMA model without exogenous variables. Then, I will proceed with training and evaluating a Prophet model as part of the overall task.


"""

# Evaluate the SARIMAX model with exogenous variables
# Calculate RMSE and MAE using the fitted values
actual_values_sarimax = ts_df_filled[results_sarimax.fittedvalues.index]
fitted_values_sarimax = results_sarimax.fittedvalues

rmse_sarimax = np.sqrt(mean_squared_error(actual_values_sarimax, fitted_values_sarimax))
mae_sarimax = mean_absolute_error(actual_values_sarimax, fitted_values_sarimax)

print("\nSARIMAX Model Performance (with Exogenous Variables) on Training Data:")
print(f"Root Mean Squared Error (RMSE): {rmse_sarimax:.4f}")
print(f"Mean Absolute Error (MAE): {mae_sarimax:.4f}")

# Compare with the optimal SARIMA model performance
print("\nComparison with Optimal SARIMA Model (without Exogenous Variables):")
print(f"Optimal SARIMA RMSE: {rmse_optimal:.4f}")
print(f"Optimal SARIMA MAE: {mae_optimal:.4f}")

# Visualize the fitted values of the SARIMAX model against the original time series
plt.figure(figsize=(15, 7))
plt.plot(ts_df_filled.index, ts_df_filled, label='Original (Filled) Time Series')
plt.plot(results_sarimax.fittedvalues.index, results_sarimax.fittedvalues, color='orange', label='SARIMAX Fitted Values')
plt.title('SARIMAX Model Fit vs. Original Time Series')
plt.xlabel('Date')
plt.ylabel('Average Water Level')
plt.legend()
plt.show()

# Plot residual diagnostics for the SARIMAX model
results_sarimax.plot_diagnostics(figsize=(15, 12))
plt.suptitle('SARIMAX Model Diagnostics (with Exogenous Variables)', y=1.02)
plt.tight_layout()
plt.show()

# Print the Ljung-Box test p-value from the SARIMAX model summary
try:
    ljung_box_pvalue_sarimax = results_sarimax.summary().tables[0].data[5][1]
    print("\nLjung-Box test p-value from SARIMAX model summary:")
    print(ljung_box_pvalue_sarimax)
except Exception as e:
    print(f"\nCould not retrieve Ljung-Box p-value from SARIMAX summary: {e}")
    print("Please manually inspect the SARIMAX summary table to find the Ljung-Box p-value.")

# Next: Prepare data and train Prophet model
